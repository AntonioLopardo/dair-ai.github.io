<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->

<head>
<meta charset="utf-8">
<title>NLP Newsletter [FR] #6: BERTology Primer, fastpages, T5, Data Science Education, PyTorch Notebooks, Slow Science in ML &#8211; dair.ai</title>
<meta name="description" content="">
<meta name="keywords" content="nlp_newsletter">


<!-- Twitter Cards -->
<meta name="twitter:title" content="NLP Newsletter [FR] #6: BERTology Primer, fastpages, T5, Data Science Education, PyTorch Notebooks, Slow Science in ML">
<meta name="twitter:description" content="">
<meta name="twitter:site" content="@dair_ai">


<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://dair.ai/images/nlp_newsletter_6.png">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP Newsletter [FR] #6: BERTology Primer, fastpages, T5, Data Science Education, PyTorch Notebooks, Slow Science in ML">
<meta property="og:description" content="">
<meta property="og:url" content="https://dair.ai/NLP_Newsletter_-6_-FR/">
<meta property="og:site_name" content="dair.ai">

<meta property="og:image" content="https://dair.ai/images/nlp_newsletter_6.png">







<link rel="canonical" href="https://dair.ai/NLP_Newsletter_-6_-FR/">
<link href="https://dair.ai/feed.xml" type="application/atom+xml" rel="alternate" title="dair.ai Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="https://dair.ai/assets/css/main.css">

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
	<script src="https://dair.ai/assets/js/vendor/html5shiv.min.js"></script>
	<script src="https://dair.ai/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="https://dair.ai/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<link href='//fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700%7CPT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="https://dair.ai/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="https://dair.ai/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="https://dair.ai/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://dair.ai/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://dair.ai/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://dair.ai/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body class="post">

<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.8&appId=1537934899816329";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>

<!-- Go to www.addthis.com/dashboard to customize your tools -->
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-4e43ef4f23bf37b0"></script>

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
		<a href="https://dair.ai/">dair.ai</a>
	</div><!-- /.site-name -->
	<div class="top-navigation">
		<nav role="navigation" id="site-nav" class="nav">
		    <ul>
		        
				    
				    <li><a href="https://dair.ai/posts/" >Blog ‚úçÔ∏è</a></li>
				
				    
				    <li><a href="https://dair.ai/about/" >About ‚ÑπÔ∏è</a></li>
				
				    
				    <li><a href="https://dair.ai/newsletter/" >NLP Newsletter üóûÔ∏è</a></li>
				
				    
				    <li><a href="https://dair.ai/projects/" >Projects üí°</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai" target="_blank">GitHub üìÅ</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/dair-ai.github.io/contribute" target="_blank">Contribute ‚ú®</a></li>
				
				    
				    <li><a href="https://medium.com/dair-ai" target="_blank">Medium üì∞</a></li>
				
				    
				    <li><a href="https://nlpoverview.com/" target="_blank">NLP Overview üìò</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/nlp_highlights" target="_blank">2019 NLP Highlights (PDF) üî•</a></li>
				
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->



<div id="main" role="main">
  <div class="article-author-side">
    

<div itemscope itemtype="http://schema.org/Person">


	<img src="https://dair.ai/images/lbourdois.png" class="bio-photo" alt="Lo√Øck BOURDOIS bio photo">


  <h3 itemprop="name">Lo√Øck BOURDOIS</h3>
  <p>Data Scientist working at the Bordeaux Population Health Research Centre of INSERM University of Bordeaux.</p>

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
</div>

  </div>
  <article class="post">
    <div class="headline-wrap">
      
        
          <h1><a href="https://dair.ai/NLP_Newsletter_-6_-FR/" rel="bookmark" title="NLP Newsletter [FR] #6: BERTology Primer, fastpages, T5, Data Science Education, PyTorch Notebooks, Slow Science in ML">NLP Newsletter [FR] #6: BERTology Primer, fastpages, T5, Data Science Education, PyTorch Notebooks, Slow Science in ML</a></h1>
        
      
    </div><!--/ .headline-wrap -->

    
    <div class="article-wrap">
      <p><img src="https://cdn-images-1.medium.com/max/1200/1*vWICxAehSy3xOnqGIXtpoQ.png" alt="" /></p>

<h1 id="avant-propos">Avant-propos</h1>
<p>Bienvenue au sixi√®me num√©ro de la lettre d‚Äôinformation consacr√©e au NLP. Merci pour votre soutien et pour avoir pris le temps de lire les derni√®res nouvelles sur le ML et le NLP. Ce num√©ro traite de sujets allant de l‚Äôextension du mod√®le Transformer au ralentissement de la publication en ML, en passant par une s√©rie de livres et de lancements de projets en ML et en NLP.</p>

<p><br />
<strong><em>Quelques mises √† jour sur la lettre d‚Äôinformation sur le NLP et sur dair.ai.</em></strong></p>

<p><br />
Nous avons traduit la lettre d‚Äôinformation dans d‚Äôautres langues telles que le portugais br√©silien, le chinois, l‚Äôarabe, l‚Äôespagnol, entre autres. Merci aux personnes qui ont aid√© √† la traduction. Vous pouvez √©galement contribuer <a href="https://github.com/dair-ai/dair-ai.github.io/issues/11">ici</a>.</p>

<p><br />
Il y a un mois, nous avons officiellement lanc√© notre nouveau <a href="https://dair.ai/">site web</a>. Vous pouvez consulter notre <a href="https://github.com/dair-ai">organisation GitHub</a> pour plus d‚Äôinformations sur dair.ai et ses projets. Si vous souhaitez voir comment d‚Äôautres personnes contribuent d√©j√† √† dair.ai ou si vous souhaitez contribuer √† la d√©mocratisation de la recherche, de l‚Äô√©ducation et des technologies en mati√®re d‚Äôintelligence artificielle, consultez notre <a href="https://github.com/dair-ai/dair-ai.github.io/issues">section</a> sur les questions d‚Äôactualit√©.</p>

<h1 id="publications--">Publications  üìô</h1>

<p><strong><em>Une introduction √† la BERTologie : Ce que nous savons sur le fonctionnement de BERT</em></strong></p>

<p><br />
Les mod√®les bas√©s sur le Transformer se sont av√©r√©s efficaces pour aborder diff√©rents types de t√¢ches de NLP allant de la classification de s√©quences √† la r√©ponse aux questions. L‚Äôun de ces mod√®les, appel√© BERT (<a href="https://arxiv.org/abs/1810.04805">Devlin et al. 2019</a>), est largement utilis√© mais comme d‚Äôautres mod√®les qui utilisent des r√©seaux de neurones profonds, nous savons tr√®s peu de choses sur leur fonctionnement interne. Un nouvel <a href="https://arxiv.org/abs/2002.12327">article</a> intitul√© ‚Äú A Primer in BERTology: What we know about how BERT works ‚Äú vise √† r√©pondre √† certaines des interrogations portant sur les raisons pour lesquelles BERT est performant dans un si grand nombre de t√¢ches de NLP. Parmi les sujets abord√©s dans cet article, on trouve le type de connaissances acquises par BERT ainsi que leur repr√©sentation, la mani√®re dont ces connaissances sont acquises et les autres m√©thodes utilis√©es par les chercheurs pour les am√©liorer.</p>

<p><br />
<strong><em>Explorer les limites de l‚Äôapprentissage par transfert avec un Transformer de texte √† texte</em></strong></p>

<p><br />
Google AI a r√©cemment publi√© une <a href="https://arxiv.org/abs/1910.10683">m√©thode</a> qui rassemble tous les enseignements et les am√©liorations tir√©s des mod√®les de NLP bas√©s sur l‚Äôapprentissage par transfert.  Les auteurs l‚Äôont appel√© Text-to-Text Transfer Transformer (T5). Ce travail propose que la plupart des t√¢ches de NLP puissent √™tre formul√©es dans un format texte-texte, sugg√©rant que les entr√©es et les sorties sont des textes. Les auteurs affirment que ce ‚Äú cadre fournit un objectif d‚Äôentra√Ænement coh√©rent √† la fois pour le pr√©-entra√Ænement et le fine-tuning‚Äù. 			
Le T5 est essentiellement un Transformer encoder-decoder qui applique diverses am√©liorations, en particulier aux composantes d‚Äôattention qui composent le mod√®le. Le mod√®le a √©t√© pr√©-entra√Æn√© sur un ensemble de donn√©es r√©cemment publi√©, le <a href="https://www.tensorflow.org/datasets/catalog/c4">Colossal Clean Crawled Corpus</a> et a √©t√© appliqu√© sur SOTA sur des t√¢ches de NLP telles que le r√©sum√©, la r√©ponse aux questions et la classification de textes.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*T9MXxcDOd2fX6xblbu7VdQ.png" alt="" /></p>

<p><a href="https://arxiv.org/abs/1910.10683"><em>(Raffel et al. 2020)</em></a></p>

<p><br />
<strong><em>12 en 1 : Apprentissage multit√¢che de la repr√©sentation de la vision et des langues</em></strong></p>

<p><br />
La recherche actuelle utilise des t√¢ches et des ensembles de donn√©es ind√©pendants pour effectuer des recherches sur la vision et le langage m√™me lorsque les ‚Äúcomp√©tences de compr√©hension du langage fond√©es sur la vision‚Äù requises pour effectuer ces t√¢ches se chevauchent. Une nouvelle <a href="https://arxiv.org/abs/1912.02315">publication</a> (qui sera pr√©sent√©e √† la CVPR) propose une approche multit√¢che √† grande √©chelle pour mieux mod√©liser et entra√Æner conjointement les t√¢ches de vision et du langage afin de g√©n√©rer un mod√®le de vision et de langue plus g√©n√©rique. Le mod√®le r√©duit la taille des param√®tres et fonctionne bien pour des t√¢ches telles que la recherche d‚Äôimages bas√©e sur des l√©gendes et la r√©ponse visuelle √† des questions.
<br />
<img src="https://cdn-images-1.medium.com/max/800/1*yyvN4bK0K2iykyJ2-QVBjw.png" alt="" /></p>

<p><a href="https://arxiv.org/abs/1912.02315"><em>(Lu et al. 2020)</em></a></p>

<p><br />
<strong><em>BERT peut voir √† l‚Äôext√©rieur de la bo√Æte : Sur la transf√©rabilit√© intermodale des repr√©sentations textuelles</em></strong></p>

<p><br />
Les chercheurs et collaborateurs de reciTAL ont publi√© un <a href="https://arxiv.org/abs/2002.10832">article</a> qui vise √† r√©pondre √† la question de savoir si un mod√®le BERT peut produire des repr√©sentations qui se g√©n√©ralisent √† d‚Äôautres modalit√©s que le texte, comme par exemple la vision. Ils proposent un mod√®le appel√© BERT-gen qui exploite des repr√©sentations mono ou multimodales et qui obtient de meilleurs r√©sultats sur les ensembles de donn√©es de g√©n√©ration de questions visuelles.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*2NgR7yBuVLDcEza9UT41dw.png" alt="" /></p>

<p><a href="https://arxiv.org/abs/2002.10832"><em>(Scialom et al. 2020)</em></a></p>

<h1 id="cr√©ativit√©-et-soci√©t√©-">Cr√©ativit√© et soci√©t√© üé®</h1>

<p><strong><em>La prochaine d√©cennie en IA : quatre √©tapes vers une intelligence artificielle robuste</em></strong></p>

<p><br />
Gary Marcus a r√©cemment publi√© un <a href="https://arxiv.org/abs/2002.06177">article</a> dans lequel il explique une s√©rie de mesures que nous devrions prendre selon lui afin de construire des syst√®mes d‚ÄôIA plus robustes. L‚Äôid√©e centrale dans ce papier est de se concentrer sur la construction de syst√®mes hybrides et ax√©s sur la connaissance, guid√©s par des mod√®les cognitifs, plut√¥t que de se concentrer sur la construction de syst√®mes plus importants qui n√©cessitent plus de donn√©es et de puissance de calcul.</p>

<p><br />
<strong><em>10 technologies de pointe pour 2020</em></strong></p>

<p><br />
La revue technologique du MIT a publi√© une liste des <a href="https://www.technologyreview.com/lists/technologies/2020/">10 perc√©es</a> qu‚Äôelle a identifi√©es et qui feront la diff√©rence dans la r√©solution de probl√®mes susceptibles de changer notre fa√ßon de vivre et de travailler. La liste - sans ordre particulier - comprend l‚Äôinternet non piratable, la m√©decine hyper-personnalis√©e, l‚Äôargent num√©rique, les m√©dicaments anti-√¢ge, les mol√©cules d√©couvertes par l‚ÄôIA, les m√©ga-constellations de satellites, la supr√©matie quantique, l‚ÄôIA minuscule, la confidentialit√© diff√©rentielle et l‚Äôattribution du climat.</p>

<p><br />
<strong><em>Il est temps de repenser le processus de publication en ML</em></strong></p>

<p><br />
Yoshua Bengio a r√©cemment fait part de ses <a href="https://yoshuabengio.org/2020/02/26/time-to-rethink-the-publication-process-in-machine-learning/">pr√©occupations</a> concernant les cycles rapides des publications du ML. La principale est qu‚Äôen raison de la rapidit√© de la publication, beaucoup d‚Äôarticles publi√©s contiennent des erreurs et sont juste incr√©mentiels. A contrario, ceux sur lesquels plus de temps est consacr√© afin d‚Äôen assurer la rigueur, semble dispara√Ætre. De plus, ce sont les √©tudiants qui doivent faire face aux cons√©quences n√©gatives de cette pression et de ce stress. Pour rem√©dier √† cette situation, Bengio parle de ses actions pour aider √† ralentir le processus de publication des recherches pour le bien de la science.</p>

<h1 id="outils-et-jeux-de-donn√©es-Ô∏è">Outils et jeux de donn√©es ‚öôÔ∏è</h1>

<p><strong><em>Mise en ≈ìuvre du r√©seau PointerGenerator dans AllenNLP</em></strong></p>

<p><br />
Les r√©seaux ¬´ Pointer-Generator ¬ª visent √† augmenter les mod√®les d‚Äôattention utilis√©s pour am√©liorer <a href="https://arxiv.org/abs/1704.04368">la synth√®se abstraite</a>. Si vous souhaitez utiliser cette technique en utilisant AllenNLP, Kundan Krishna a d√©velopp√© une <a href="https://github.com/kukrishna/pointer-generator-pytorch-allennlp">librairie</a> qui vous permet d‚Äôex√©cuter un mod√®le pr√©-entra√Æn√© (fourni) ou d‚Äôentra√Æner votre propre mod√®le.</p>

<p><br />
<strong><em>Questions/r√©ponses pour diff√©rentes langues</em></strong></p>

<p><br />
Avec la prolif√©ration des mod√®les de Transformer et leur efficacit√© pour les t√¢ches de NLP, des efforts impressionnants ont √©t√© d√©ploy√©s pour publier diff√©rents types de jeux de donn√©es dans diff√©rentes langues. Par exemple, Sebastian Ruder a <a href="https://twitter.com/seb_ruder/status/1231713840502657025?s=20">partag√© une liste</a> de jeux de donn√©es qui peuvent √™tre utilis√©s pour des t√¢ches de r√©ponses aux questions dans diff√©rentes langues : <a href="https://www.aclweb.org/anthology/W18-2605/">DuReader</a>, <a href="https://arxiv.org/abs/1909.07005">KorQuAD</a>, <a href="https://arxiv.org/abs/1912.09723">SberQuAD</a>, <a href="https://arxiv.org/abs/2002.06071">FQuAD</a>, <a href="https://arxiv.org/abs/1906.05394">Arabic-SQuAD</a>, <a href="https://github.com/crux82/squad-it">SQuAD-it</a> et <a href="https://arxiv.org/abs/1912.05200v2">Spanish SQuAD</a>.</p>

<p><br />
<strong><em>PyTorch Lightning</em></strong></p>

<p><br />
PyTorch Lightning est un <a href="https://towardsdatascience.com/from-pytorch-to-pytorch-lightning-a-gentle-introduction-b371b7caaf09">outil</a> qui vous permet de r√©aliser un entra√Ænement abstrait qui n√©cessiterait l‚Äôutilisation de GPU/TPU d‚Äôune pr√©cision de 16 bits. PyTorch Lightning permet d‚Äôentra√Æner des mod√®les sur des plusieurs GPU et TPU sans avoir besoin de changer votre code PyTorch actuel.</p>

<p><br />
<strong><em>Graph Neural Networks dans TensorFlow 2</em></strong></p>

<p><br />
Une √©quipe de recherche de Microsoft publie une <a href="https://github.com/microsoft/tf2-gnn">librairie</a> qui donne acc√®s aux impl√©mentations de nombreuses architectures de r√©seaux neuronaux en graphes (GNN). Cette librairie est bas√©e sur TensorFlow 2 et fournit √©galement des modules de manipulation de donn√©es qui peuvent √™tre directement utilis√©s dans des boucles d‚Äôentrainement/√©valuation.</p>

<p><br />
<strong><em>Pr√©-entra√Ænement de SmallBERTa - Un petit mod√®le pour s‚Äôentra√Æner sur un petit jeu de donn√©es</em></strong></p>

<p><br />
Avez-vous d√©j√† voulu entra√Æner votre propre mod√®le linguistique √† partir de z√©ro mais n‚Äôavez pas eu assez de ressources pour le faire ? Si c‚Äôest le cas, Aditya Malte vous propose un <a href="https://gist.github.com/aditya-malte/2d4f896f471be9c38eb4d723a710768b#file-smallberta_pretraining-ipynb">notebook</a> qui vous apprend √† entrainer un mod√®le linguistique √† partir de z√©ro avec un ensemble de donn√©es plus restreint.</p>

<h1 id="ethique-en-ia-">Ethique en IA üö®</h1>

<p><strong><em>Pourquoi les visages ne disent pas toujours la v√©rit√© sur les sentiments</em></strong></p>

<p><br />
Depuis un certain temps, de nombreux chercheurs et entreprises ont tent√© de construire des mod√®les d‚ÄôIA qui comprennent et peuvent reconna√Ætre les √©motions dans un contexte textuel ou visuel. Un nouvel <a href="https://www.nature.com/articles/d41586-020-00507-5">article</a> relance le d√©bat sur le fait que les techniques d‚ÄôIA qui visent √† reconna√Ætre les √©motions √† partir des images de visages ne le font pas correctement. L‚Äôargument principal, soulev√© par des psychologues, est qu‚Äôil n‚Äôexiste aucune preuve d‚Äôexpressions universelles pouvant √™tre utilis√©es pour la d√©tection d‚Äô√©motions bas√©es uniquement sur des images de visages. Il faudrait qu‚Äôun mod√®le comprenne mieux par exemple les traits de personnalit√© ou encore les mouvements du corps, afin de se rapprocher r√©ellement d‚Äôune d√©tection plus pr√©cise des √©motions affich√©es par les humains.</p>

<p><br />
<strong><em>Differential Privacy and Federated Learning Explained</em></strong></p>

<p><br />
L‚Äôune des consid√©rations √©thiques √† prendre en compte lors de la construction de syst√®mes d‚ÄôIA est la garantie du respect de la vie priv√©e. Actuellement, cela peut √™tre r√©alis√© de deux mani√®res, soit en utilisant une intimit√© diff√©rentielle, soit par un apprentissage f√©d√©r√©. Si vous voulez en savoir plus sur ces sujets, Jordan Harrod nous fournit une excellente introduction dans cette <a href="https://www.youtube.com/watch?v=MOcTGM_UteM">vid√©o</a> qui comprend √©galement une session de pratique avec l‚Äôutilisation d‚Äôun notebook.</p>

<h1 id="articles-et-blog-Ô∏è">Articles et Blog ‚úçÔ∏è</h1>

<p><strong><em>Plong√©e dans le Reformer</em></strong></p>

<p><br />
Madison May a √©crit un nouvel <a href="https://www.pragmatic.ml/reformer-deep-dive/">article sur son blog</a> consacr√© au <a href="https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html">Reformer</a>, propos√© par Google AI. Nous avons √©galement pr√©sent√© le Reformer dans un <a href="https://medium.com/dair-ai/nlp-newsletter-reformer-deepmath-electra-tinybert-for-search-vizseq-open-sourcing-ml-68d5b6eed057">pr√©c√©dent num√©ro</a> de la newsletter. Pour une explication en fran√ßais, vous pouvez consulter l‚Äôillustration <a href="https://lbourdois.github.io/blog/nlp/Reformer/">suivante</a>.</p>

<p><br />
<strong><em>Une plateforme de blogging gratuite</em></strong></p>

<p><br />
<a href="https://fastpages.fast.ai/fastpages/jupyter/2020/02/21/introducing-fastpages.html">fastpages</a> vous permet de cr√©er automatiquement et gratuitement un blog en utilisant les pages GitHub. Cette solution simplifie le processus de publication d‚Äôun blog et prend √©galement en charge l‚Äôutilisation de documents Word et de notebook Jupyter.</p>

<p><br />
<strong><em>Conseils pour un entretien chez Google</em></strong></p>

<p><br />
Pablo Castro, de l‚Äô√©quipe Google Brain, a publi√© un <a href="https://psc-g.github.io/interviews/google/2020/02/25/interviewing-at-google.html">article sur son blog</a> mettant en avant une liste de conseils pour les personnes int√©ress√©es par un entretien d‚Äôembauche chez Google. Parmi les sujets abord√©s figurent des conseils sur la fa√ßon de se pr√©parer √† l‚Äôentretien, sur ce √† quoi il faut s‚Äôattendre pendant l‚Äôentretien et sur ce qui se passe apr√®s l‚Äôentretien.</p>

<p><br />
<strong><em>Les Transformers sont des Graph Neural Networks</em></strong></p>

<p><br />
Les r√©seaux neuronaux de graphes (GNN) et les Transformers se sont av√©r√©s efficaces pour diff√©rentes t√¢ches de NLP. Pour mieux comprendre le fonctionnement interne de ces approches et leurs relations, Chaitanya Joshi a √©crit un <a href="https://graphdeeplearning.github.io/post/transformers-are-gnns/">article</a> expliquant la connexion entre les GNN et les Transformers, ainsi que les diff√©rentes fa√ßons dont ces m√©thodes peuvent √™tre combin√©es dans une sorte de mod√®le hybride.</p>

<p><br />
<strong><em>CNNs et Equivariance</em></strong></p>

<p><br />
Fabian Fuchs et Ed Wagstaff <a href="https://fabianfuchsml.github.io/equivariance1of2/">discutent</a> de l‚Äôimportance de l‚Äô√©quivariance et de la mani√®re dont les CNN la font respecter. Le concept d‚Äô√©quivariance est d‚Äôabord d√©fini, puis discut√© dans le contexte de CNN appliqu√©s √† la traduction.</p>

<p><br />
<strong><em>L‚Äôauto-apprentissage avec les images</em></strong></p>

<p><br />
L‚Äôauto-apprentissage a √©t√© beaucoup √©voqu√© dans les pr√©c√©dents num√©ros de la newsletter en raison du r√¥le qu‚Äôil a jou√© dans les techniques modernes de mod√©lisation des langues. Ce <a href="https://datasciencecastnet.home.blog/2020/02/22/self-supervised-learning-with-image%e7%bd%91/">billet</a> de Jonathan Whitaker fournit une explication de l‚Äôauto-apprentissage dans le contexte des images. Si le sujet vous int√©resse, Amit Chaudhary a √©galement √©crit un <a href="https://amitness.com/2020/02/illustrated-self-supervised-learning/">article</a> d√©crivant le concept de mani√®re visuelle.</p>

<h1 id="education-">Education üéì</h1>
<p><strong><em>Stanford CS330: Deep Multi-Task et Meta-Learning</em></strong></p>

<p><br />
Stanford a r√©cemment publi√© une <a href="https://www.youtube.com/playlist?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5">playlist vid√©o YouTube</a> sur son nouveau cours consacr√© √† l‚Äôapprentissage multi-t√¢ches et au m√©ta-apprentissage. Parmi les sujets abord√©s, citons le m√©ta-apprentissage bay√©sien, le lifelong apprentissage, une introduction √† l‚Äôapprentissage par renforcement, etc‚Ä¶</p>

<p><br />
<strong><em>Notebooks PyTorch</em></strong></p>

<p><br />
dair.ai publie une <a href="https://github.com/dair-ai/pytorch_notebooks">s√©rie de notebook</a> qui visent √† vous faire d√©couvrir les r√©seaux neuronaux profonds √† l‚Äôaide de PyTorch. Il s‚Äôagit d‚Äôun travail en cours et certains sujets d‚Äôactualit√© comprennent la fa√ßon de mettre en ≈ìuvre un mod√®le de r√©gression logistique √† partir de z√©ro et la fa√ßon de programmer un NN ou un RNN √† partir de z√©ro. Les notebooks sont √©galement disponibles dans le d√©p√¥t GitHub.</p>

<p><br />
<em>**Le livre de fastai book (√©bauche) **</em></p>

<p><br />
Jeremy Howard et Sylvain Gugger ont publi√© une <a href="https://github.com/fastai/fastbook">liste compl√®te</a> de notebooks (non termin√©s) en vue de leur prochain cours qui pr√©sentera des concepts de deep learning et diff√©rentes m√©thodes d‚Äôutilisation de PyTorch et la librairie fastai.</p>

<p><br />
<strong><em>Cours gratuits sur la datascience</em></strong></p>

<p><br />
Au cas o√π vous l‚Äôauriez manqu√©, Kaggle propose une s√©rie de <a href="https://www.kaggle.com/learn/overview">petits cours gratuits</a> sur les outils de datascience. Certains de ces cours comprennent, entre autres, l‚Äôexplication de l‚Äôapprentissage machine, une introduction √† l‚Äôapprentissage machine et √† Python, la visualisation de donn√©es, l‚Äôing√©nierie des fonctionnalit√©s et l‚Äôapprentissage approfondi.</p>

<p><br />
Un autre <a href="https://lewtun.github.io/dslectures/">cours de datascience en ligne</a> propose un programme, des diapositives et des notebooks sur l‚Äôanalyse exploratoire des donn√©es, l‚Äôinterpr√©tation des mod√®les ou encore le NLP.</p>

<p><br />
<strong><em>8 cr√©ateurs et contributeurs parlent de leurs librairies PyTorch</em></strong></p>

<p><br />
nepture.ai a publi√© un vaste <a href="https://neptune.ai/blog/model-training-libraries-pytorch-ecosystem?utm_source=twitter&amp;utm_medium=tweet&amp;utm_campaign=blog-model-training-libraries-pytorch-ecosystem">article</a> qui contient des discussions d√©taill√©es avec les principaux cr√©ateurs et contributeurs de PyTorch (parcours, philosophie du projet, outils qui l‚Äôentourent, etc‚Ä¶).</p>

<p><br />
<strong><em>Visualisation des mod√®les adaptatifs d‚Äôattention r√©duite</em></strong></p>

<p><br />
Sasha Rush partage un <a href="https://colab.research.google.com/drive/1EB7MI_3gzAR1gFwPPO27YU9uYzE_odSu">notebook</a> qui explique et montre les d√©tails techniques sur la mani√®re de produire des sorties softmax sparses. Il aborde √©galement la fa√ßon d‚Äôinduire la sparcit√© dans la composante d‚Äôattention d‚Äôun mod√®le de Transformer, ce qui aide √† produire une probabilit√© nulle pour les mots non pertinents dans un contexte donn√©, am√©liorant ainsi la performance et l‚Äôinterpr√©tabilit√©.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*7BB322LlVgt1zzk-cviSoA.png" alt="" /></p>

<h1 id="mentions-sp√©ciales-Ô∏è">Mentions sp√©ciales ‚≠êÔ∏è</h1>

<p>Conor Bell a cod√© un <a href="https://gist.github.com/connorbell/9269401d127f1e507cc9aaf2803067c4">script python</a> qui vous permet de visualiser et de pr√©parer facilement un jeu de donn√©es pouvant √™tre utilis√© pour un mod√®le StyleGAN.</p>

<p><br />
Manu Romero <a href="https://github.com/huggingface/transformers/tree/master/model_cards/mrm8488/bert-spanish-cased-finetuned-pos">a contribu√©</a> au fine-tuning d‚Äôun mod√®le POS pour l‚Äôespagnol. Le mod√®le est sur la librairie Transfomers d‚ÄôHugging Face. Il sera int√©ressant de voir cet effort dans d‚Äôautres langues.</p>

<p><br />
Ce <a href="https://github.com/tomohideshibata/BERT-related-papers">r√©pertoire Github</a> contient une longue liste de documents r√©dig√©s sur BERT qui abordent diff√©rents probl√®mes tels que la compression de mod√®les, les domaines sp√©cifiques, le multi-mod√®le, la g√©n√©ration, les t√¢ches en aval, etc.</p>

<p><br />
Connor Shorten a publi√© une courte <a href="https://www.youtube.com/watch?time_continue=79&amp;v=-Bh_7tzyoR4&amp;feature=emb_logo">vid√©o</a> de 15 minutes expliquant un framework √† aborder pour r√©duire l‚Äôeffet des ‚Äúraccourcis‚Äù dans l‚Äôauto-apprentissage de la repr√©sentation. C‚Äôest important car, s‚Äôil n‚Äôest pas bien fait, le mod√®le peut ne pas apprendre des repr√©sentations s√©mantiques utiles et se r√©v√©ler potentiellement inefficace dans un contexte d‚Äôapprentissage par transfert.</p>

<p><br />
Sebastian Ruder a publi√© un nouveau num√©ro de sa newsletter qui met en lumi√®re des sujets et des ressources allant d‚Äôanalyses d‚Äôarticles sur le NLP et le ML de 2019 √† des diapositives sur l‚Äôapprentissage par transfert et des √©l√©ments essentiels sur le deep learning. Vous pouvez le consulter <a href="http://newsletter.ruder.io/issues/accelerating-science-memorizing-vs-learning-to-look-things-up-schmidhuber-s-2010s-greek-bert-arc-illustrated-reformer-annotated-gpt-2-olmpics-223195">ici</a>.</p>

<hr />

<p>Vous pouvez retrouver la pr√©c√©dente newsletter <a href="https://dair.ai/NLP_Newsletter_-5_-FR/">ici</a></p>

<p><br />
Si vous avez des jeux de donn√©es, des projets, des articles de blog, des tutoriels ou des documents que vous souhaitez partager dans la prochaine √©dition de la newletter, n‚Äôh√©sitez pas √† me contacter √† ellfae@gmail.com ou par message sur <a href="https://twitter.com/omarsar0">Twitter</a>.</p>

<p><br />
<a href="https://dair.ai/newsletter/">Abonnez-vous</a> pour recevoir les prochains num√©ros dans votre bo√Æte mail.</p>

      <hr />
      <footer role="contentinfo">
        <div class="social-share">
  <!-- Go to www.addthis.com/dashboard to customize your tools --> 
  <div class="addthis_inline_share_toolbox"></div>
  <!--
  <h4>Share on</h4>
  <ul>
    <li>
      <a href="https://twitter.com/intent/tweet?text=https://dair.ai/NLP_Newsletter_-6_-FR/" class="twitter" title="Share on Twitter"><i class="fa fa-twitter"></i><span> Twitter</span></a>
    </li>
    <li>
      <a href="https://www.facebook.com/sharer/sharer.php?u=https://dair.ai/NLP_Newsletter_-6_-FR/" class="facebook" title="Share on Facebook"><i class="fa fa-facebook"></i><span> Facebook</span></a>
    </li>
    <li>
      <a href="https://plus.google.com/share?url=https://dair.ai/NLP_Newsletter_-6_-FR/" class="google-plus" title="Share on Google Plus"><i class="fa fa-google-plus"></i><span> Google+</span></a>
    </li>
  </ul>-->
</div><!-- /.social-share -->
        <p class="byline"><strong>NLP Newsletter [FR] #6: BERTology Primer, fastpages, T5, Data Science Education, PyTorch Notebooks, Slow Science in ML</strong> was published on <time datetime="2020-03-09T00:00:00-05:00">March 09, 2020</time>.</p>
        
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dair-ai'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<!--
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->

      </footer>
    </div><!-- /.article-wrap -->
  
    <section id="disqus_thread"></section><!-- /#disqus_thread -->
  
  </article>
</div><!-- /#main -->

<div class="footer-wrap">
  
  <div class="related-articles">
  <h4>You might also enjoy <small class="pull-right">(<a href="https://dair.ai/posts/">View all posts</a>)</small></h4>
    <ul>
    
      <li><a href="https://dair.ai/NLP_Newsletter_NLP_7-ZH-.md/" title="NLP ÁÆÄÊä•ÔºàIssue#7Ôºâ: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶">NLP ÁÆÄÊä•ÔºàIssue#7Ôºâ: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶</a></li>
    
      <li><a href="https://dair.ai/NLP_Newsletter_NLP_7/" title="NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶">NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶</a></li>
    
      <li><a href="https://dair.ai/NLP_Newsletter_-7_-FR/" title="NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶">NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶</a></li>
    
    </ul>
    <hr />
  </div><!-- /.related-articles -->
  
  <footer>
    

<span>&copy; 2020 dair.ai. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="http://mademistakes.com/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a> theme.</span>

  </footer>
</div><!-- /.footer-wrap -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="https://dair.ai/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="https://dair.ai/assets/js/scripts.min.js"></script>

<!-- Asynchronous Google Analytics snippet -->
<script>
  var _gaq = _gaq || [];
  var pluginUrl =
 '//www.google-analytics.com/plugins/ga/inpage_linkid.js';
  _gaq.push(['_require', 'inpage_linkid', pluginUrl]);
  _gaq.push(['_setAccount', 'UA-158959084-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<script async defer src="https://buttons.github.io/buttons.js"></script>


  
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dair-ai'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<!--
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->




</body>
</html>
