<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->

<head>
<meta charset="utf-8">
<title>NLP Newsletter [FR] #3: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,‚Ä¶ &#8211; dair.ai</title>
<meta name="description" content="">
<meta name="keywords" content="nlp_newsletter">


<!-- Twitter Cards -->
<meta name="twitter:title" content="NLP Newsletter [FR] #3: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,‚Ä¶">
<meta name="twitter:description" content="">
<meta name="twitter:site" content="@dair_ai">


<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://localhost:4000/images/nlp_newsletter_3.png">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP Newsletter [FR] #3: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,‚Ä¶">
<meta property="og:description" content="">
<meta property="og:url" content="http://localhost:4000/NLP_Newsletter_-3_-FR/">
<meta property="og:site_name" content="dair.ai">

<meta property="og:image" content="http://localhost:4000/images/nlp_newsletter_3.png">







<link rel="canonical" href="http://localhost:4000/NLP_Newsletter_-3_-FR/">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="dair.ai Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
	<script src="http://localhost:4000/assets/js/vendor/html5shiv.min.js"></script>
	<script src="http://localhost:4000/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<link href='//fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700%7CPT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://localhost:4000/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body class="post">

<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.8&appId=1537934899816329";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>

<!-- Go to www.addthis.com/dashboard to customize your tools -->
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-4e43ef4f23bf37b0"></script>

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
		<a href="http://localhost:4000/">dair.ai</a>
	</div><!-- /.site-name -->
	<div class="top-navigation">
		<nav role="navigation" id="site-nav" class="nav">
		    <ul>
		        
				    
				    <li><a href="http://localhost:4000/posts/" >Blog ‚úçÔ∏è</a></li>
				
				    
				    <li><a href="http://localhost:4000/about/" >About ‚ÑπÔ∏è</a></li>
				
				    
				    <li><a href="http://localhost:4000/newsletter/" >NLP Newsletter üóûÔ∏è</a></li>
				
				    
				    <li><a href="http://localhost:4000/projects/" >Projects üí°</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai" target="_blank">GitHub üìÅ</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/dair-ai.github.io/contribute" target="_blank">Contribute ‚ú®</a></li>
				
				    
				    <li><a href="https://medium.com/dair-ai" target="_blank">Medium üì∞</a></li>
				
				    
				    <li><a href="https://nlpoverview.com/" target="_blank">NLP Overview üìò</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/nlp_highlights" target="_blank">2019 NLP Highlights (PDF) üî•</a></li>
				
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->



<div id="main" role="main">
  <div class="article-author-side">
    

<div itemscope itemtype="http://schema.org/Person">


	<img src="http://localhost:4000/images/lbourdois.png" class="bio-photo" alt="Lo√Øck BOURDOIS bio photo">


  <h3 itemprop="name">Lo√Øck BOURDOIS</h3>
  <p>Data Scientist working at the Bordeaux Population Health Research Centre of INSERM University of Bordeaux.</p>

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
</div>

  </div>
  <article class="post">
    <div class="headline-wrap">
      
        
          <h1><a href="http://localhost:4000/NLP_Newsletter_-3_-FR/" rel="bookmark" title="NLP Newsletter [FR] #3: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,‚Ä¶">NLP Newsletter [FR] #3: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,‚Ä¶</a></h1>
        
      
    </div><!--/ .headline-wrap -->

    
    <div class="article-wrap">
      <p><img src="https://cdn-images-1.medium.com/max/2400/1*qaOM0D2tfy3chvnWRdycGA.png" alt="" /></p>

<h1 id="avant-propos">Avant-propos</h1>
<p>Bienvenue √† la Newsletter sur le NLP ! Le troisi√®me num√©ro traite de sujets tels que l‚Äôam√©lioration des agents conversationnels, les versions de BERT sp√©cifiques √† chaque langue, les ensembles de donn√©es gratuits, les versions des biblioth√®ques d‚Äôapprentissage approfondi, et bien plus encore.</p>

<h1 id="publications-">Publications üìô</h1>

<p><strong><em>Versions de BERT sp√©cifiques √† chaque langue</em></strong></p>

<p><br />
J‚Äôai perdu le compte du nombre de mod√®les BERT sp√©cifiques √† chaque langue, mais voici quelques-unes des versions r√©centes :</p>
<ul>
  <li>BERT n√©erlandais (<a href="https://arxiv.org/abs/2001.06286">RobBERT</a>, <a href="https://arxiv.org/abs/1912.09582">BERTje</a>)</li>
  <li><a href="https://deepset.ai/german-bert">BERT allemand</a></li>
  <li><a href="https://github.com/neuralmind-ai/portuguese-bert">BERT portugais</a></li>
  <li>BERT fran√ßais (<a href="https://arxiv.org/abs/1911.03894">CamemBERT</a>, <a href="https://arxiv.org/abs/1912.05372">FlauBERT</a>)</li>
  <li>BERT italien (<a href="http://ceur-ws.org/Vol-2481/paper57.pdf">AlBERTo</a>, <a href="https://github.com/musixmatchresearch/umberto">UmBERTo</a>)</li>
  <li>BERT espagnol (<a href="https://github.com/dccuchile/beto">BETO</a>)</li>
  <li>BERT arabe (<a href="https://colab.research.google.com/drive/1KSy89fAkWt6EGfnFQElDjXrBror9lIZh">araBERT</a>)</li>
</ul>

<p><br />
Notez que la plupart de ces mod√®les sont √©galement disponibles par le biais de la librairie de Transformers d‚ÄôHugging Face, qui a r√©cemment √©t√© mise √† jour avec la version <a href="https://github.com/huggingface/transformers/releases">2.4.1</a>.</p>

<p><br />
<strong><em>R√©sultats trop optimistes de pr√©dictions sur des donn√©es d√©s√©quilibr√©es : d√©fauts et avantages de l‚Äôapplication du sur-√©chantillonnage</em></strong></p>

<p><br />
Cette <a href="https://arxiv.org/abs/2001.06296">publication</a> r√©v√®le et examine en d√©tail certains des d√©fauts et des avantages de l‚Äôapplication du sur-√©chantillonnage pour traiter les jeux de donn√©es d√©s√©quilibr√©s avant de les partitionner. En outre, le travail reproduit des √©tudes ant√©rieures et identifie cette faille m√©thodologique qui produit des r√©sultats trop optimistes.</p>

<p><br />
<strong><em>Encoder, √©tiqueter et r√©aliser : une approche contr√¥lable et efficace pour la g√©n√©ration de texte</em></strong></p>

<p><br />
Afin de r√©duire l‚Äôeffet d‚Äô<a href="https://arxiv.org/abs/1910.08684">hallucination</a> (production de sorties non support√©es par le texte d‚Äôentr√©e) commun aux m√©thodes de g√©n√©ration de texte bas√©es sur seq2seq, un groupe d‚Äôing√©nieurs de Google a ouvert une m√©thode de g√©n√©ration de texte appel√©e <a href="https://ai.googleblog.com/2020/01/encode-tag-and-realize-controllable-and.html">LaserTagger</a>.
L‚Äôid√©e principale de cette m√©thode est de produire des sorties en marquant des mots avec des op√©rations d‚Äô√©dition pr√©dites (par exemple, KEEP, DELETE-ADD,, etc.) et en les appliquant aux mots d‚Äôentr√©e dans une √©tape dite de r√©alisation. Cette m√©thode remplace celle de g√©n√©ration de texte courante qui ne fait que g√©n√©rer des sorties √† partir de z√©ro, ce qui est g√©n√©ralement lent et sujet √† des erreurs. Le mod√®le offre d‚Äôautres avantages en plus de g√©n√©rer moins d‚Äôerreurs, tels que la possibilit√© de pr√©voir en parall√®le les op√©rations d‚Äô√©dition tout en conservant une bonne pr√©cision et en surpassant une base de r√©f√©rence BERT dans des sc√©narios avec un nombre r√©duit d‚Äôexemples d‚Äôentra√Ænement.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/1600/0*OJN4pNgrQoS2STAX.png" alt="" /></p>

<p>‚Ää<a href="https://ai.googleblog.com/2020/01/encode-tag-and-realize-controllable-and.html"><em>source</em></a></p>

<p><br />
<strong><em>Les r√©seaux neuronaux convolutifs comme mod√®le du syst√®me visuel : pass√©, pr√©sent et futur</em></strong></p>

<p><br />
Grace Lindsay a publi√© ce <a href="https://arxiv.org/abs/2001.07092">rapport</a> sur l‚Äôhistoire des CNN et sur la mani√®re dont ils sont √©valu√©s en tant que mod√®les de vision biologique, c‚Äôest-√†-dire comment les repr√©sentations des CNN se comparent √† celles du cerveau ? La discussion sur les nouvelles possibilit√©s d‚Äôutilisation des CNN pour la recherche sur la vision est vivement recommand√©e aux lecteurs.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/1600/1*SngMqzPQJigR5A3AzeJGDQ.png" alt="" /></p>

<p><a href="https://arxiv.org/abs/2001.07092"><em>source</em></a></p>

<p><br />
<strong><em>Multilingual Denoising Pre-training for Neural Machine Translation</em></strong></p>

<p><br />
Facebook AI a publi√© <a href="https://arxiv.org/pdf/2001.08210.pdf">mBART</a>, une m√©thode bas√©e sur un auto-encodeur de d√©bruitage multilingue seq2seq pr√©-entrain√© sur des corpus monolingues √† grande √©chelle pour la traduction automatique dans 25 langues.
Le texte d‚Äôentr√©e implique le masquage des phrases et la permutation des phrases (bruits). Un mod√®le bas√© sur un Transformer est appris pour reconstruire le texte dans plusieurs langues. Le mod√®le autor√©gressif complet n‚Äôest entra√Æn√© qu‚Äôune seule fois et peut √™tre ajust√© sur n‚Äôimporte quelle paire de langues sans impliquer de modifications sp√©cifiques √† la t√¢che ou √† la langue. Les probl√®mes de traduction au niveau du document et de la phrase sont abord√©s. En plus de montrer des gains de performance, les auteurs affirment que la m√©thode fonctionne bien sur la traduction automatique √† faible ressource.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/1600/1*aigX70Om2rEaI7OoTcpyGA.png" alt="" /></p>

<p><a href="https://arxiv.org/pdf/2001.08210.pdf"><em>source</em></a></p>

<p><br />
<strong><em>Sur l‚Äôam√©lioration des agents conversationnels</em></strong></p>

<p><br />
<a href="https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html">Meena</a> est un agent conversationnel qui vise √† mener des conversations plus sensibles et plus sp√©cifiques ;  des mesures d√©finies pour saisir les attributs importants d‚Äôune conversation humaine (par exemple, la fluidit√©). Le mod√®le apprend le contexte de la conversation via un encodeur et formule une r√©ponse sensible via le d√©codeur. Il est signal√© que l‚Äôam√©lioration de la qualit√© des conversations a √©t√© possible en consid√©rant des d√©codeurs plus puissants.</p>

<p><br />
Vous pouvez √©galement prendre connaissance des <a href="https://venturebeat.com/2020/01/31/with-googles-meena-are-ai-assistants-about-to-get-a-lot-smarter/">r√©flexions</a> d‚ÄôAlan Nichol (co-fondateur du si√®ge de Rasa) sur ce travail.</p>

<h1 id="cr√©ativit√©-et-soci√©t√©-">Cr√©ativit√© et soci√©t√© üé®</h1>

<p><strong><em>Test de compr√©hension de la lecture et analyseur de sentiments</em></strong></p>

<p><br />
Ming Cheuk a con√ßu cette <a href="https://littlealbert.now.sh/#/">application</a> qui permet de tester les capacit√©s de compr√©hension de lecture d‚Äô<a href="https://ai.googleblog.com/2019/12/albert-lite-bert-for-self-supervised.html">ALBERT</a>. ALBERT est une version plus petite de BERT pour l‚Äôapprentissage des repr√©sentations des langues. L‚Äôauteur explique plus en d√©tail le projet et les approches utilis√©es dans ce <a href="https://www.spark64.com/post/machine-comprehension">blog</a>.</p>

<p><br />
Hendrik Strobelt a √©galement publi√© un petit <a href="https://github.com/HendrikStrobelt/sentimenter_minimal_hai">projet</a> dans lequel il montre comment r√©aliser un prototype d‚Äôun analyseur de sentiments interactif.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/1600/1*kgKeL3svHqScr0Wjnfe0Cg.png" alt="" /></p>

<p><a href="https://littlealbert.now.sh/#/"><em>source</em></a></p>

<p><br />
<strong><em>Le parcours d‚Äôun chercheur autodidacte sur l‚ÄôIA chez Google</em></strong></p>

<p><br />
Dans cet <a href="https://blog.floydhub.com/emils-story-as-a-self-taught-ai-researcher/">entretien</a> Emil, un chercheur de ML √† Google Art &amp; Culture, parle de son parcours en tant que chercheur autodidacte.</p>

<h1 id="outils-et-jeux-de-donn√©es-Ô∏è">Outils et jeux de donn√©es ‚öôÔ∏è</h1>

<p><strong><em>Jeux de donn√©es en libre acc√®s</em></strong></p>

<p><br />
<a href="https://blog.google/products/search/discovering-millions-datasets-web/">Google Dataset Search</a> fournit d√©sormais jusqu‚Äô√† 25 millions de jeux de donn√©es. Il s‚Äôagit essentiellement d‚Äôun moteur de recherche pour les ensembles de donn√©es.</p>

<p><br />
La base de donn√©es <a href="https://quantumstat.com/dataset/dataset.html">Big Bad NLP</a> est un site web o√π vous pouvez rechercher une base de donn√©es d√©di√©e de plus de 200 jeux de donn√©es de NLP de tous types pour des t√¢ches telles que le raisonnement, l‚Äôanalyse des sentiments, la r√©ponse aux questions, l‚Äôinf√©rence d‚Äôimplication, etc‚Ä¶</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/1600/1*uYwA0snqOdKYyTJ56edtyA.png" alt="" /></p>

<p><br />
<strong><em>Librairie d‚Äôapprentissage par renforcement</em></strong></p>

<p><br />
Chris Nota a d√©velopp√© et publi√© une <a href="https://github.com/cpnota/autonomous-learning-library">librairie PyTorch</a> pour la construction d‚Äôagents d‚Äôapprentissage par renforcement bas√©s sur des algorithmes populaires tels que DQN, PPO et DDPG. L‚Äôaccent de la librairie est mis sur la conception orient√©e objet et sur la mise en ≈ìuvre et l‚Äô√©valuation rapides de nouveaux agents d‚Äôapprentissage par renforcement.</p>

<p><br />
<strong><em>Explicabilit√© et interpr√©tabilit√© du ML</em></strong></p>

<p><br />
Si vous travaillez actuellement avec des mod√®les linguistiques bas√©s sur des textes et que vous souhaitez comprendre comment les interpr√©ter plus facilement lorsqu‚Äôils sont appliqu√©s √† diff√©rentes t√¢ches linguistiques, alors vous pourriez √™tre int√©ress√© par <a href="https://captum.ai/">Captum</a>. Captum est une librairie d‚Äôinterpr√©tabilit√© qui peut √™tre utilis√©e pour analyser l‚Äôimportance des caract√©ristiques, interpr√©ter des mod√®les de texte et de vision, interpr√©ter des mod√®les multimodaux, et d‚Äôautres mod√®les tels que BERT utilis√© pour la r√©ponse aux questions.</p>

<p><br />
Si vous vous int√©ressez √† l‚Äôexplicabilit√© des mod√®les, cet <a href="https://www.kaggle.com/learn/machine-learning-explainability">tutoriels</a> peuvent √©galement vous int√©resser.</p>

<p><br />
<strong><em>Libraries de ML et DL</em></strong></p>

<p><br />
L‚Äô√©quipe de Google Research a publi√© <a href="https://github.com/google-research/flax/tree/prerelease">Flax</a>, une libririe de r√©seaux neuronaux flexible et puissante bas√©e sur <a href="https://github.com/google/jax">JAX</a> qui fournit un framework pour le calcul rapide et l‚Äôentra√Ænement de mod√®les de ML en utilisant les API typiques de Numpy.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/1600/1*LSWFZM-xMV-GnvGl_lC-sg.png" alt="" /></p>

<p><em>Flax syntax</em></p>

<p><br />
<a href="https://thinc.ai/">Thinc</a> est une librairie l√©g√®re de deep learning d√©velopp√©e par les cr√©ateurs de spaCy. Elle offre des API de programmation fonctionnelle pour composer, configurer et d√©ployer des mod√®les personnalis√©s construits avec des librairies comme PyTorch et TensorFlow.</p>

<p><br />
Lyft lance <a href="https://eng.lyft.com/introducing-flyte-cloud-native-machine-learning-and-data-processing-platform-fb2bb3046a59">Flyte</a>, une plateforme, pr√™te pour la production et sans serveur, pour le d√©ploiement dde travail de traitement de donn√©es et de ML.</p>

<p><br />
<strong><em>Un outil pour l‚ÄôIA conversationnelle</em></strong></p>

<p><br />
<a href="https://github.com/deepmipt/DeepPavlov">DeepPavlov</a> offre une solution gratuite et facile √† utiliser pour la construction de syst√®mes de dialogue et de syst√®mes conversationnels complexes. DeepPavlov est livr√© avec plusieurs composants pr√©d√©finis pour r√©soudre les probl√®mes li√©s au NLP. Il int√®gre BERT (y compris le BERT conversationnel) dans trois t√¢ches : la classification de textes, la reconnaissance d‚Äôentit√©s nomm√©es (et le marquage des s√©quences en g√©n√©ral) et la r√©ponse aux questions. En cons√©quence, il a permis d‚Äôam√©liorer consid√©rablement toutes ces t√¢ches. (<a href="https://colab.research.google.com/github/deepmipt/dp_notebooks/blob/master/DP_tf.ipynb">Google Colab</a> | <a href="https://medium.com/tensorflow/deeppavlov-an-open-source-library-for-end-to-end-dialog-systems-and-chatbots-31cf26849e37">Blog</a> | <a href="https://demo.deeppavlov.ai/#/en/textqa">D√©mo</a>).</p>

<h1 id="ethique-en-ia-">Ethique en IA üö®</h1>
<p><strong><em>Reconnaissance faciale et vie priv√©e</em></strong></p>

<p><br />
Le New York Times a r√©dig√© un article sur les diff√©rentes perspectives concernant la vie priv√©e impliquant la technologie de reconnaissance faciale. Ce reportage porte sur une ‚Äúsoci√©t√© secr√®te‚Äù appel√©e Clearview qui utiliserait la technologie d‚ÄôIA pour construire une reconnaissance faciale universelle √† partir d‚Äôimages r√©cup√©r√©es sur les r√©seaux sociaux tels que Twitter, Facebook et YouTube, etc‚Ä¶ Cette technologie soul√®ve des inqui√©tudes quant au respect de la vie priv√©e, mais elle serait √©galement utilis√©e principalement pour l‚Äôapplication de la loi. Pour en savoir plus, cliquez <a href="https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html">ici</a>.</p>

<p><br />
<strong><em>Progr√®s de l‚ÄôIA au niveau humain</em></strong></p>

<p><br />
Dans cet <a href="https://fortune.com/longform/ai-artificial-intelligence-big-tech-microsoft-alphabet-openai/">article</a>, Jeremy Kahn discute en d√©tail de la diff√©rence entre ¬´ l‚ÄôIA √©troite ¬ª et ¬´ l‚ÄôIA g√©n√©rale ¬ª dans le contexte des progr√®s actuels de la technologie. Outre les nombreux sujets abord√©s, de nombreuses questions se posent sur les b√©n√©fices de la r√©alisation de l‚ÄôIA g√©n√©rale. L‚Äôarticle mentionne √©galement l‚Äôint√©r√™t r√©cent des grandes entreprises technologiques qui investissent dans ces efforts. L‚Äôarticle inclut plusieurs pr√©occupations soulev√©es par des chercheurs respect√©s qui d√©noncent le comportement ‚Äúirresponsable et contraire √† l‚Äô√©thique‚Äù de certains organismes de recherche qui tentent de manipuler les r√©cits sur l‚ÄôIA √† leur profit.</p>

<p><br />
<strong><em>Technologies d‚ÄôIA pr√©servant la vie priv√©e</em></strong></p>

<p><br />
L‚Äôun des efforts men√© afin de promouvoir une IA ethique, responsable et respectant la vie priv√©e est celui de la communaut√© [OpenMined] https://twitter.com/OpenMinedOrg). Si vous voulez en savoir plus, vous pouvez √©couter Andrew Trask, parler de cette initiative dans cette <a href="https://www.youtube.com/watch?v=4zrU54VIK6k">vid√©o</a> faisant partie de la s√©rie de conf√©rences du MIT sur l‚Äôapprentissage profond.</p>

<p><br />
<strong><em>Comprendre l‚Äô√©thique et la s√©curit√©</em></strong></p>

<p><br />
Le Dr David Leslie a publi√© ce <a href="https://www.turing.ac.uk/sites/default/files/2019-06/understanding_artificial_intelligence_ethics_and_safety.pdf">rapport</a> tr√®s d√©taill√© sur des sujets qui aident √† mieux comprendre l‚ÄôIA dans le contexte de l‚Äô√©thique et de la s√©curit√©. Il vise √† aider les d√©veloppeurs et les chercheurs √† mieux concevoir et mettre en ≈ìuvre des syst√®mes d‚ÄôIA pour le secteur public.
<img src="https://cdn-images-1.medium.com/max/1600/1*Ye09aVDP93RKsLc12PXqNQ.png" alt="" /></p>

<p><a href="https://www.turing.ac.uk/sites/default/files/2019-06/understanding_artificial_intelligence_ethics_and_safety.pdf"><em>source</em></a></p>

<h1 id="articles-et-blog-Ô∏è">Articles et Blog ‚úçÔ∏è</h1>
<p><strong><em>Tutoriel sur l‚Äôacc√©l√©ration de la tokenisation</em></strong></p>

<p><br />
Steven van de Graaf a √©crit cet [article] https://towardsdatascience.com/a-small-timing-experiment-on-the-new-tokenizers-library-a-write-up-7caab6f80ea6) √† propos des performances de la librairie <a href="https://github.com/huggingface/tokenizers">Tokenizers</a> d‚ÄôHugging Face par rapport au tokenizer standard int√©gr√© utilis√© dans la librairie <a href="https://github.com/huggingface/transformers">Transformers</a>. Steven constate qu‚Äôune impl√©mentation prend 10,6 secondes pour tokenizer 1 million de phrases et que le temps d‚Äôex√©cution est divis√© par 9.</p>

<p><br />
<strong><em>Les mod√®les linguistiques peuvent-ils vraiment comprendre ?</em></strong></p>

<p><br />
The Gradient a r√©cemment publi√© ce <a href="https://thegradient.pub/gpt2-and-the-nature-of-intelligence/">post</a> de Gary Marcus o√π il discute de ce qu‚Äôil croit √™tre des d√©fauts fondamentaux derri√®re des mod√®les de langage comme GPT-2. L‚Äôargument principal de Gary Marcus est qu‚Äôun mod√®le entra√Æn√© pour pouvoir pr√©dire le mot suivant n‚Äôest pas n√©cessairement un mod√®le capable de comprendre ou de raisonner. C‚Äôest-√†-dire que ‚Äúla pr√©diction est une composante de la compr√©hension, pas l‚Äôensemble‚Äù.</p>

<p><br />
<strong><em>Curriculum for Reinforcement Learning</em></strong></p>

<p><br />
Lillian Weng <a href="https://lilianweng.github.io/lil-log/2020/01/29/curriculum-for-reinforcement-learning.html">r√©sume</a> plusieurs approches bas√©es sur les curriculum et la fa√ßon dont cela peut √™tre utilis√© pour entra√Æner de fa√ßon efficace des agents d‚Äôapprentissage par renforcement. Weng aborde les d√©fis de la conception d‚Äôune telle approche, qui n√©cessite g√©n√©ralement de trier la complexit√© des t√¢ches et de fournir au mod√®le une s√©quence de t√¢ches dont le niveau de difficult√© augmente au cours de l‚Äôentra√Ænement.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/1600/0*B-t_sNMjKiOb_Y3Z.png" alt="" /></p>

<p><a href="https://lilianweng.github.io/lil-log/2020/01/29/curriculum-for-reinforcement-learning.html"><em>source</em></a></p>

<p><br />
<strong><em>Introduction √† NumPy</em></strong></p>

<p><br />
Anne Bonner a r√©cemment publi√© ce tutoriel d√©taill√© pr√©sentant les bases de <a href="https://numpy.org/devdocs/user/absolute_beginners.html">NumPy</a>. Il est constitue une base solide pour les personnes souhaitant s‚Äôinitier √† cette librairie.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/1600/0*FmUSU_dh-_cqGUk_.png" alt="" /></p>

<p><a href="https://numpy.org/devdocs/user/absolute_beginners.html"><em>source</em></a></p>

<h1 id="education-">Education üéì</h1>
<p><strong><em>Fondements de l‚Äôapprentissage machine et de l‚Äôinf√©rence statistique</em></strong></p>

<p><br />
Anima Anandkumar, du Caltech, a publi√© un cours intitul√© ‚ÄúFondements de l‚Äôapprentissage machine et de l‚Äôinf√©rence statistique‚Äù. Le cours se concentre sur les concepts de ML tels que les matrices, les tenseurs, l‚Äôoptimisation, les mod√®les probabilistes, les r√©seaux de neurones et bien plus encore. Ce cours aborde les aspects th√©oriques du ML. (<a href="https://www.youtube.com/playlist?list=PLVNifWxslHCDlbyitaLLYBOAEPbmF1AHg">la playlist vid√©o</a> | <a href="http://tensorlab.cms.caltech.edu/users/anima/cms165-2020.html">le programme du cours</a>)</p>

<p><br />
<strong><em>S√©rie de conf√©rences sur le DL</em></strong></p>

<p><br />
DeepMind s‚Äôest associ√© √† l‚ÄôUCL pour lancer une <a href="https://www.eventbrite.co.uk/o/ucl-x-deepmind-deep-learning-lecture-series-general-29078980901">s√©rie de 12 conf√©rences</a> sur l‚Äôapprentissage profond donn√©es par des chercheurs de DeepMind.</p>

<p><br />
<strong><em>~7 million de programmes d‚Äô√©tudes</em></strong></p>

<p><br />
<a href="https://opensyllabus.org/">Open Syllabus</a> est une organisation √† but non lucratif qui utilise le crowdsourcing pour mettre en place un programme d‚Äôenseignement sup√©rieur dans une base de donn√©es en ligne. Elle contient actuellement environ sept millions de programmes.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/1600/1*fwQIhfb2VWuwQJM_LaLehg.png" alt="" /></p>

<p><a href="https://opensyllabus.org/results-list/titles?size=50&amp;fields=Computer%20Science"><em>source</em></a></p>

<p><br />
<strong><em>Discuter, partager et apprendre sur le ML</em></strong></p>

<p><br />
<a href="https://www.reddit.com/r/ResearchML/">r/ResearchML</a> est une nouvelle sous-rubrique de reddit consacr√© au ML. Celui-ci est davantage ax√© sur la recherche et encourage des discussions plus approfondies.</p>

<h1 id="mentions-sp√©ciales-Ô∏è">Mentions sp√©ciales ‚≠êÔ∏è</h1>

<p>D√©couvrez comment <a href="https://github.blog/2020-01-22-how-we-built-good-first-issues/">GitHub</a> exploite l‚Äôapprentissage machine pour rep√©rer les probl√®mes faciles et personnalis√©s des d√©veloppeurs afin qu‚Äôils puissent s‚Äôattaquer aux questions qui correspondent √† leurs int√©r√™ts. Cela encourage des contributions plus rapides et plus nombreuses de la part des contributeurs de logiciels libres.</p>

<p><br />
Sebastian Ruder a publi√© une nouvelle <a href="http://newsletter.ruder.io/issues/nlp-progress-restrospectives-and-look-ahead-new-nlp-courses-independent-research-initiatives-interviews-lots-of-resources-217744">newsletter</a>. On y trouve une mise √† jour des progr√®s du NLP, des r√©trospectives sur la derni√®re d√©cennie, de nouveaux cours de NLP, et d‚Äôautres sujets.</p>

<p><br />
Jetez un coup d‚Äô≈ìil √† <a href="https://github.com/NERSC/dl4sci-tf-tutorials">ces notebooks TensorFlow 2.0</a> qui vont de CycleGAN √† Transformers en passant par les t√¢ches de sous-titrage d‚Äôimages. Ils ont √©t√© rendus publics par l‚Äô√©cole d‚Äôapprentissage profond pour la science du LBNL.</p>

<p><br />
Un <a href="https://engineering.papercup.com/posts/bayesian-neural-nets/">blog</a> pour s‚Äôinitier aux r√©seaux neuronaux bay√©siens.</p>

<p><br />
John Schulman <a href="http://joschu.net/blog/opinionated-guide-ml-research.html">partage</a> quelques conseils pour les futurs chercheurs du LBNL sur la fa√ßon de mieux choisir les probl√®mes de recherche et d‚Äô√™tre plus strat√©gique dans la r√©alisation des t√¢ches de recherche. John partage √©galement des conseils pour le d√©veloppement personnel et le progr√®s continu.</p>

<hr />

<p>Vous pouvez retrouver la pr√©c√©dente newsletter <a href="https://dair.ai/NLP_Newsletter_-2_-FR/">ici</a></p>

<p><br />
Si vous avez des jeux de donn√©es, des projets, des articles de blog, des tutoriels ou des documents que vous souhaitez partager dans la prochaine √©dition de la newletter, n‚Äôh√©sitez pas √† me contacter √† ellfae@gmail.com ou par message sur <a href="https://twitter.com/omarsar0">Twitter</a>.</p>

<p><br />
<a href="https://dair.ai/newsletter/">Abonnez-vous</a> pour recevoir les prochains num√©ros dans votre bo√Æte mail.</p>

      <hr />
      <footer role="contentinfo">
        <div class="social-share">
  <!-- Go to www.addthis.com/dashboard to customize your tools --> 
  <div class="addthis_inline_share_toolbox"></div>
  <!--
  <h4>Share on</h4>
  <ul>
    <li>
      <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/NLP_Newsletter_-3_-FR/" class="twitter" title="Share on Twitter"><i class="fa fa-twitter"></i><span> Twitter</span></a>
    </li>
    <li>
      <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/NLP_Newsletter_-3_-FR/" class="facebook" title="Share on Facebook"><i class="fa fa-facebook"></i><span> Facebook</span></a>
    </li>
    <li>
      <a href="https://plus.google.com/share?url=http://localhost:4000/NLP_Newsletter_-3_-FR/" class="google-plus" title="Share on Google Plus"><i class="fa fa-google-plus"></i><span> Google+</span></a>
    </li>
  </ul>-->
</div><!-- /.social-share -->
        <p class="byline"><strong>NLP Newsletter [FR] #3: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,‚Ä¶</strong> was published on <time datetime="2020-03-09T00:00:00+01:00">March 09, 2020</time>.</p>
        
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dair-ai'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<!--
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->

      </footer>
    </div><!-- /.article-wrap -->
  
    <section id="disqus_thread"></section><!-- /#disqus_thread -->
  
  </article>
</div><!-- /#main -->

<div class="footer-wrap">
  
  <div class="related-articles">
  <h4>You might also enjoy <small class="pull-right">(<a href="http://localhost:4000/posts/">View all posts</a>)</small></h4>
    <ul>
    
      <li><a href="http://localhost:4000/NLP_Newsletter_NLP_7-ZH-.md/" title="NLP ÁÆÄÊä•ÔºàIssue#7Ôºâ: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶">NLP ÁÆÄÊä•ÔºàIssue#7Ôºâ: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶</a></li>
    
      <li><a href="http://localhost:4000/NLP_Newsletter_NLP_7/" title="NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶">NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶</a></li>
    
      <li><a href="http://localhost:4000/NLP_Newsletter_-7_-FR/" title="NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶">NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,‚Ä¶</a></li>
    
    </ul>
    <hr />
  </div><!-- /.related-articles -->
  
  <footer>
    

<span>&copy; 2020 dair.ai. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="http://mademistakes.com/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a> theme.</span>

  </footer>
</div><!-- /.footer-wrap -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>

<!-- Asynchronous Google Analytics snippet -->
<script>
  var _gaq = _gaq || [];
  var pluginUrl =
 '//www.google-analytics.com/plugins/ga/inpage_linkid.js';
  _gaq.push(['_require', 'inpage_linkid', pluginUrl]);
  _gaq.push(['_setAccount', 'UA-158959084-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<script async defer src="https://buttons.github.io/buttons.js"></script>


  
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dair-ai'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<!--
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->




</body>
</html>
