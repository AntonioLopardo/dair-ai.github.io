<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>All Posts &#8211; dair.ai</title>
<meta name="description" content="A List of Posts">
<meta name="keywords" content="">


<!-- Twitter Cards -->
<meta name="twitter:title" content="All Posts">
<meta name="twitter:description" content="A List of Posts">
<meta name="twitter:site" content="@dair_ai">
<meta name="twitter:creator" content="@dair_ai">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://localhost:4000/images/avatar-background.png">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="All Posts">
<meta property="og:description" content="A List of Posts">
<meta property="og:url" content="http://localhost:4000/posts/">
<meta property="og:site_name" content="dair.ai">

<meta property="og:image" content="http://localhost:4000/images/avatar-background.png">







<link rel="canonical" href="http://localhost:4000/posts/">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="dair.ai Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
	<script src="http://localhost:4000/assets/js/vendor/html5shiv.min.js"></script>
	<script src="http://localhost:4000/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<link href='//fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700%7CPT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://localhost:4000/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body class="post-index">

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
		<a href="http://localhost:4000/">dair.ai</a>
	</div><!-- /.site-name -->
	<div class="top-navigation">
		<nav role="navigation" id="site-nav" class="nav">
		    <ul>
		        
				    
				    <li><a href="http://localhost:4000/posts/" >Blog ✍️</a></li>
				
				    
				    <li><a href="http://localhost:4000/about/" >About ℹ️</a></li>
				
				    
				    <li><a href="http://localhost:4000/newsletter/" >NLP Newsletter 🗞️</a></li>
				
				    
				    <li><a href="http://localhost:4000/projects/" >Projects 💡</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai" target="_blank">GitHub 📁</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/dair-ai.github.io/contribute" target="_blank">Contribute ✨</a></li>
				
				    
				    <li><a href="https://medium.com/dair-ai" target="_blank">Medium 📰</a></li>
				
				    
				    <li><a href="https://nlpoverview.com/" target="_blank">NLP Overview 📘</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/nlp_highlights" target="_blank">2019 NLP Highlights (PDF) 🔥</a></li>
				
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->



<div id="main" role="main">
  <div class="article-author-side">
    

<div itemscope itemtype="http://schema.org/Person">


	<img src="http://localhost:4000/images/dair-ai.png" class="bio-photo" alt="dair.ai bio photo">


  <h3 itemprop="name">dair.ai</h3>
  <p>Democratizing Artificial Intelligence Research, Education, and Technologies</p>

  <a href="http://twitter.com/dair_ai" class="author-social" target="_blank"><i class="fa fa-fw fa-twitter-square"></i> Twitter</a>
  
  
  
  
  
  
  <a href="http://github.com/dair-ai" class="author-social" target="_blank"><i class="fa fa-fw fa-github"></i> Github</a>
  
  
  
  
  
  
  
  
  
  
</div>

  </div>
  <div id="index">
    <h1>All Posts</h1>
    
    
      <!--<h3>2020</h3>-->
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_NLP_7-ZH-.md/" title="NLP 简报（Issue#7）: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…">NLP 简报（Issue#7）: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…</a></h2>
          <!--<p>在本期中，我们涵盖的主题包括了从如何改进测量成分泛化到计算机视觉PyTorch库到最新的物理模拟器等.</p>-->
          <!--<p class="byline"> <time datetime="2020-03-16T00:00:00+01:00">March 16, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_NLP_7/" title="NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…">NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…</a></h2>
          <!--<p>In this issue, we cover topics that range from improving how to measure compositional generalization to a computer vision PyTorch library to a state-of-the-a...</p>-->
          <!--<p class="byline"> <time datetime="2020-03-16T00:00:00+01:00">March 16, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_-7_-FR/" title="NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…">NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…</a></h2>
          <!--<p>

</p>-->
          <!--<p class="byline"> <time datetime="2020-03-16T00:00:00+01:00">March 16, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_-6_-FR/" title="NLP Newsletter [FR] #6: BERTology Primer, fastpages, T5, Data Science Education, PyTorch Notebooks, Slow Science in ML">NLP Newsletter [FR] #6: BERTology Primer, fastpages, T5, Data Science Education, PyTorch Notebooks, Slow Science in ML</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-03-09T00:00:00+01:00">March 09, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_-5_-FR/" title="NLP Newsletter [FR] #5: The Annotated GPT-2, Understanding self-distillation, Haiku, GANILLA, Sparkwiki, Ethics in NLP, Torchmeta,…">NLP Newsletter [FR] #5: The Annotated GPT-2, Understanding self-distillation, Haiku, GANILLA, Sparkwiki, Ethics in NLP, Torchmeta,…</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-03-09T00:00:00+01:00">March 09, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_-4_-FR/" title="NLP Newsletter [FR] #4: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,…">NLP Newsletter [FR] #4: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,…</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-03-09T00:00:00+01:00">March 09, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_-3_-FR/" title="NLP Newsletter [FR] #3: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,…">NLP Newsletter [FR] #3: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,…</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-03-09T00:00:00+01:00">March 09, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_-2_-FR/" title="NLP Newsletter [FR] #2: Reformer, DeepMath, ELECTRA, TinyBERT, VizSeq, Open-Sourcing ML,…">NLP Newsletter [FR] #2: Reformer, DeepMath, ELECTRA, TinyBERT, VizSeq, Open-Sourcing ML,…</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-03-09T00:00:00+01:00">March 09, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_-1_-FR/" title="NLP Newsletter [FR] #1: Tokenizers, TensorFlow 2.1, TextVectorization, TorchIO, NLP Shortfalls,…">NLP Newsletter [FR] #1: Tokenizers, TensorFlow 2.1, TextVectorization, TorchIO, NLP Shortfalls,…</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-03-09T00:00:00+01:00">March 09, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP%E7%AE%80%E6%8A%A5/" title="NLP 简报（Issue#6）">NLP 简报（Issue#6）</a></h2>
          <!--<p>本期涵盖的主题范围从扩展Transformer模型到建议减缓ML发表速度到一系列ML和NLP书籍和项目发行。</p>-->
          <!--<p class="byline"> <time datetime="2020-03-02T00:00:00+01:00">March 02, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_BERTology_Primer_fastpages_T5/" title="NLP Newsletter #6: BERTology Primer, fastpages, T5, Data Science Education, PyTorch Notebooks, Slow Science in ML">NLP Newsletter #6: BERTology Primer, fastpages, T5, Data Science Education, PyTorch Notebooks, Slow Science in ML</a></h2>
          <!--<p>This issue covers topics that range from extending the Transformer model to slowing publication in ML to a series of ML and NLP books and project releases.</p>-->
          <!--<p class="byline"> <time datetime="2020-03-02T00:00:00+01:00">March 02, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter-PT-BR-_BERTology_Primer_fastpages_T5/" title="NLP Newsletter [PT-BR] #6: BERTology Primer, fastpages, T5, Data Science Education, PyTorch Notebooks, Slow Science in ML">NLP Newsletter [PT-BR] #6: BERTology Primer, fastpages, T5, Data Science Education, PyTorch Notebooks, Slow Science in ML</a></h2>
          <!--<p>Essa edição cobre tópicos como extensões ao modelo Transformer, desaceleração no processo de publicação em Aprendizado de Máquina, divulgação de livros e pro...</p>-->
          <!--<p class="byline"> <time datetime="2020-03-02T00:00:00+01:00">March 02, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP%E7%AE%80%E6%8A%A5-Issue-5-The_Annotated_GPT-2-CodeBERT-JAX-GA/" title="NLP简报（Issue#5）：The Annotated GPT-2、CodeBERT、JAX、GANILLA等">NLP简报（Issue#5）：The Annotated GPT-2、CodeBERT、JAX、GANILLA等</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-02-29T00:00:00+01:00">February 29, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter-PT-BR-_The_Annotated_GPT-2,_Understanding/" title="NLP Newsletter: GPT-2 Anotado, Entendendo self-distillation, Haiku, GANILLA, Sparkwiki, Ética em NLP, Torchmeta,…">NLP Newsletter: GPT-2 Anotado, Entendendo self-distillation, Haiku, GANILLA, Sparkwiki, Ética em NLP, Torchmeta,…</a></h2>
          <!--<p>Esta edição abrange tópicos como a compreensão de self-distillation, tradução de imagem para ilustração, considerações éticas para modelos de NLP, etc.</p>-->
          <!--<p class="byline"> <time datetime="2020-02-29T00:00:00+01:00">February 29, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter.AR._The_Annotated_GPT-2_And_More/" title="الإصدار الخامس من قائمة معالجة اللغات الطبيعية (NLP) البريدية: GPT-2 المشروح، فهم التقطير-الذاتي، Haiku، GANILLA، Sparkwiki، الأخلاق في علم معالجة اللغات الطبيعية، Torchmeta، والمزيد ...">الإصدار الخامس من قائمة معالجة اللغات الطبيعية (NLP) البريدية: GPT-2 المشروح، فهم التقطير-الذاتي، Haiku، GANILLA، Sparkwiki، الأخلاق في علم معالجة اللغات الطبيعية، Torchmeta، والمزيد ...</a></h2>
          <!--<p>هذا العدد يغطي مواضيع مثل: فهم التقطير-الذاتي (Self-Distillation)، ترجمة صورة-إلى-رسمة (Image-to-illustration Translation)، الاعتبارات الأخلاقية في علم معالج...</p>-->
          <!--<p class="byline"> <time datetime="2020-02-28T00:00:00+01:00">February 28, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_The_Annotated_GPT-2,_Understanding/" title="NLP Newsletter #5: The Annotated GPT-2, Understanding self-distillation, Haiku, GANILLA, Sparkwiki, Ethics in NLP, Torchmeta,…">NLP Newsletter #5: The Annotated GPT-2, Understanding self-distillation, Haiku, GANILLA, Sparkwiki, Ethics in NLP, Torchmeta,…</a></h2>
          <!--<p>This issue covers topics such as understanding self-distillation, image-to-illustration translation, ethical considerations for NLP models, etc.</p>-->
          <!--<p class="byline"> <time datetime="2020-02-23T00:00:00+01:00">February 23, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/Bolet%C3%ADn_informativo_NLP_GPT-2_Explicado,_Entendie/" title="Boletín informativo NLP #5: GPT-2 Explicado, Entendiendo ‘Self-Distillation’, Haiku, GANILLA, Sparkwiki, Ética en el NLP, Torchmeta,...">Boletín informativo NLP #5: GPT-2 Explicado, Entendiendo ‘Self-Distillation’, Haiku, GANILLA, Sparkwiki, Ética en el NLP, Torchmeta,...</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-02-23T00:00:00+01:00">February 23, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/Fundamentals-of-NLP-Chapter-1/" title="Fundamentals of NLP (Chapter 1): Tokenization, Lemmatization, Stemming, and Sentence Segmentation">Fundamentals of NLP (Chapter 1): Tokenization, Lemmatization, Stemming, and Sentence Segmentation</a></h2>
          <!--<p>In this first chapter of the Fundamentals of NLP series, we will learn about lemmatization, stemming, tokenization, and sentence segmentation.</p>-->
          <!--<p class="byline"> <time datetime="2020-02-21T00:00:00+01:00">February 21, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP%E7%AE%80%E6%8A%A5_Tokenizers,_TensorFlow_2_1,_TextVectorization/" title="NLP简报 [CH]: Tokenizers, TensorFlow 2.1, TextVectorization, TorchIO, NLP Shortfalls,…">NLP简报 [CH]: Tokenizers, TensorFlow 2.1, TextVectorization, TorchIO, NLP Shortfalls,…</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-02-20T00:00:00+01:00">February 20, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP%E7%AE%80%E6%8A%A5_ISSUE_4_PyTorch3D,_DeepSpeed,_Turing-NLG/" title="NLP简报 [CH]: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,…">NLP简报 [CH]: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,…</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-02-17T00:00:00+01:00">February 17, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_PyTorch3D,_DeepSpeed,_Turing-NLG/" title="NLP Newsletter #4: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,…">NLP Newsletter #4: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,…</a></h2>
          <!--<p>This issue covers topics such as bigger language models, improving 3D deep learning research, multilingual question answering benchmark, auditing AI systems,...</p>-->
          <!--<p class="byline"> <time datetime="2020-02-16T00:00:00+01:00">February 16, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter-PT-BR-_PyTorch3D,_DeepSpeed,_Turing-NLG/" title="NLP Newsletter [PT-BR]: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,…">NLP Newsletter [PT-BR]: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,…</a></h2>
          <!--<p>Essa edição cobre tópicos como modelos de linguagem maiores, avanços na pesquisa de Deep Learning em 3D, benchmarks para question answering multi-idiomas, au...</p>-->
          <!--<p class="byline"> <time datetime="2020-02-16T00:00:00+01:00">February 16, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP%E7%AE%80%E6%8A%A5_Flax,_Thinc,_Language-specific_BERT_models/" title="NLP简报 [CH]: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,…">NLP简报 [CH]: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,…</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-02-15T00:00:00+01:00">February 15, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_Flax,_Thinc,_Language-specific_BERT/" title="NLP Newsletter #3: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,…">NLP Newsletter #3: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,…</a></h2>
          <!--<p>The third issue covers topics such as improving conversational agents, releases of language-specific BERT models, free datasets, releases of deep learning li...</p>-->
          <!--<p class="byline"> <time datetime="2020-02-01T00:00:00+01:00">February 01, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP%E7%AE%80%E6%8A%A5_Reformer,_DeepMath,_ELECTRA,_TinyBERT/" title="NLP简报 [CH]: Reformer, DeepMath, ELECTRA, TinyBERT for Search, VizSeq, Open-Sourcing ML,…">NLP简报 [CH]: Reformer, DeepMath, ELECTRA, TinyBERT for Search, VizSeq, Open-Sourcing ML,…</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-01-19T00:00:00+01:00">January 19, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_Reformer,_DeepMath,_ELECTRA,_TinyB-copy/" title="NLP Newsletter #1: Reformer, DeepMath, ELECTRA, TinyBERT for Search, VizSeq, Open-Sourcing ML,…">NLP Newsletter #1: Reformer, DeepMath, ELECTRA, TinyBERT for Search, VizSeq, Open-Sourcing ML,…</a></h2>
          <!--<p>This second issue covers topics that range from model interpretability to protein folding to active transfer learning.</p>-->
          <!--<p class="byline"> <time datetime="2020-01-19T00:00:00+01:00">January 19, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter-PT-BR-_Reformer,_DeepMath,_ELECTRA,_TinyB/" title="NLP Newsletter: Reformer, DeepMath, ELECTRA, TinyBERT para busca, VizSeq, Open-Sourcing ML,…">NLP Newsletter: Reformer, DeepMath, ELECTRA, TinyBERT para busca, VizSeq, Open-Sourcing ML,…</a></h2>
          <!--<p>Esta segunda newsletter aborda topics que vão de interpretabilidade de modelos para enovelamento de proteínas (protein folding) até active transfer learning</p>-->
          <!--<p class="byline"> <time datetime="2020-01-19T00:00:00+01:00">January 19, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter_Tokenizers,_TensorFlow_2_1,_TextVe/" title="NLP Newsletter #1: Tokenizers, TensorFlow 2.1, TextVectorization, TorchIO, NLP Shortfalls,…">NLP Newsletter #1: Tokenizers, TensorFlow 2.1, TextVectorization, TorchIO, NLP Shortfalls,…</a></h2>
          <!--<p>This edition covers a series of improved NLP pipelines, NLP shortfalls, an AI system for breast cancer screening,…</p>-->
          <!--<p class="byline"> <time datetime="2020-01-12T00:00:00+01:00">January 12, 2020</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/NLP_Newsletter-PT-BR-_Tokenizers,_TensorFlow_2_1,_TextVe/" title="NLP Newsletter [PT-BR]: Tokenizadores, TensorFlow 2.1, Vetorização de Texto, TorchIO, Déficits de NLP,…">NLP Newsletter [PT-BR]: Tokenizadores, TensorFlow 2.1, Vetorização de Texto, TorchIO, Déficits de NLP,…</a></h2>
          <!--<p></p>-->
          <!--<p class="byline"> <time datetime="2020-01-12T00:00:00+01:00">January 12, 2020</time></p>-->
        

      </article>
    
    
        
        
        
          <!--<h3>2019</h3>-->
        
      
      <article>
        
          <h2><a href="http://localhost:4000/nlp-highlights-2018/" title="NLP 2018 Highlights (Free 70+ Pages PDF Report)">NLP 2018 Highlights (Free 70+ Pages PDF Report)</a></h2>
          <!--<p>NLP 2018 Highlights</p>-->
          <!--<p class="byline"> <time datetime="2019-01-10T00:00:00+01:00">January 10, 2019</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/emnlp-emotion-recognition/" title="EMNLP 2018 Oral Presentation on Affective Computing (Emotion Recognition)">EMNLP 2018 Oral Presentation on Affective Computing (Emotion Recognition)</a></h2>
          <!--<p>EMNLP 2018 Oral Presentation on Affective Computing (Emotion Recognition)</p>-->
          <!--<p class="byline"> <time datetime="2019-01-10T00:00:00+01:00">January 10, 2019</time></p>-->
        

      </article>
    
    
        
        
        
          <!--<h3>2018</h3>-->
        
      
      <article>
        
          <h2><a href="http://localhost:4000/bias-in-sentiment-analysis/" title="Examining Gender and Race Bias in Sentiment Analysis Systems">Examining Gender and Race Bias in Sentiment Analysis Systems</a></h2>
          <!--<p>Examining Gender and Race Bias in Sentiment Analysis Systems</p>-->
          <!--<p class="byline"> <time datetime="2018-12-22T00:00:00+01:00">December 22, 2018</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/nlp-overview/" title="Modern Deep Learning Techniques Applied to Natural Language Processing">Modern Deep Learning Techniques Applied to Natural Language Processing</a></h2>
          <!--<p>Modern Deep Learning Techniques Applied to Natural Language Processing</p>-->
          <!--<p class="byline"> <time datetime="2018-10-24T00:00:00+02:00">October 24, 2018</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/deep-learning-emotion-recognition-pytorch-tensorflow/" title="Deep Learning Based Emotion Recognition with PyTorch and TensorFlow">Deep Learning Based Emotion Recognition with PyTorch and TensorFlow</a></h2>
          <!--<p>Deep Learning Based Emotion Recognition with PyTorch and TensorFlow</p>-->
          <!--<p class="byline"> <time datetime="2018-10-19T00:00:00+02:00">October 19, 2018</time></p>-->
        

      </article>
    
    
        
        
        
      
      <article>
        
          <h2><a href="http://localhost:4000/deep-learning-for-nlp-pytorch-tensorflow/" title="Deep Learning for NLP: PyTorch vs Tensorflow – PyCon Taiwan 2018">Deep Learning for NLP: PyTorch vs Tensorflow – PyCon Taiwan 2018</a></h2>
          <!--<p>Deep Learning for NLP: PyTorch vs Tensorflow – PyCon Taiwan 2018</p>-->
          <!--<p class="byline"> <time datetime="2018-08-11T00:00:00+02:00">August 11, 2018</time></p>-->
        

      </article>
    
  </div><!-- /#index -->
</div><!-- /#main -->

<div class="footer-wrap">
  <footer>
    

<span>&copy; 2020 dair.ai. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="http://mademistakes.com/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a> theme.</span>

  </footer>
</div><!-- /.footer-wrap -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>

<!-- Asynchronous Google Analytics snippet -->
<script>
  var _gaq = _gaq || [];
  var pluginUrl =
 '//www.google-analytics.com/plugins/ga/inpage_linkid.js';
  _gaq.push(['_require', 'inpage_linkid', pluginUrl]);
  _gaq.push(['_setAccount', 'UA-158959084-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<script async defer src="https://buttons.github.io/buttons.js"></script>




</body>
</html>
