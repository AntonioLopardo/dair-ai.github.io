<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->

<head>
<meta charset="utf-8">
<title>NLP简报 [CH]: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,… &#8211; dair.ai</title>
<meta name="description" content="">
<meta name="keywords" content="nlp_newsletter">


<!-- Twitter Cards -->
<meta name="twitter:title" content="NLP简报 [CH]: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,…">
<meta name="twitter:description" content="">
<meta name="twitter:site" content="@dair_ai">
<meta name="twitter:creator" content="@omarsar0">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://localhost:4000/images/nlp_newsletter_3.png">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP简报 [CH]: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,…">
<meta property="og:description" content="">
<meta property="og:url" content="http://localhost:4000/NLP%E7%AE%80%E6%8A%A5_Flax,_Thinc,_Language-specific_BERT_models/">
<meta property="og:site_name" content="dair.ai">

<meta property="og:image" content="http://localhost:4000/images/nlp_newsletter_3.png">







<link rel="canonical" href="http://localhost:4000/NLP%E7%AE%80%E6%8A%A5_Flax,_Thinc,_Language-specific_BERT_models/">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="dair.ai Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
	<script src="http://localhost:4000/assets/js/vendor/html5shiv.min.js"></script>
	<script src="http://localhost:4000/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<link href='//fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700%7CPT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://localhost:4000/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body class="post">

<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.8&appId=1537934899816329";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>

<!-- Go to www.addthis.com/dashboard to customize your tools -->
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-4e43ef4f23bf37b0"></script>

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
		<a href="http://localhost:4000/">dair.ai</a>
	</div><!-- /.site-name -->
	<div class="top-navigation">
		<nav role="navigation" id="site-nav" class="nav">
		    <ul>
		        
				    
				    <li><a href="http://localhost:4000/posts/" >Blog ✍️</a></li>
				
				    
				    <li><a href="http://localhost:4000/about/" >About ℹ️</a></li>
				
				    
				    <li><a href="http://localhost:4000/newsletter/" >NLP Newsletter 🗞️</a></li>
				
				    
				    <li><a href="http://localhost:4000/projects/" >Projects 💡</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai" target="_blank">GitHub 📁</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/dair-ai.github.io/contribute" target="_blank">Contribute ✨</a></li>
				
				    
				    <li><a href="https://medium.com/dair-ai" target="_blank">Medium 📰</a></li>
				
				    
				    <li><a href="https://nlpoverview.com/" target="_blank">NLP Overview 📘</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/nlp_highlights" target="_blank">2019 NLP Highlights (PDF) 🔥</a></li>
				
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->



<div id="main" role="main">
  <div class="article-author-side">
    

<div itemscope itemtype="http://schema.org/Person">


	<img src="http://localhost:4000/images/white_background_elvis.png" class="bio-photo" alt="Elvis Saravia bio photo">


  <h3 itemprop="name">Elvis Saravia</h3>
  <p>Editor at dair.ai</p>

  <a href="http://twitter.com/omarsar0" class="author-social" target="_blank"><i class="fa fa-fw fa-twitter-square"></i> Twitter</a>
  
  
  
  
  
  
  <a href="http://github.com/omarsar" class="author-social" target="_blank"><i class="fa fa-fw fa-github"></i> Github</a>
  
  
  
  
  
  
  
  
  
  
</div>

  </div>
  <article class="post">
    <div class="headline-wrap">
      
        
          <h1><a href="http://localhost:4000/NLP%E7%AE%80%E6%8A%A5_Flax,_Thinc,_Language-specific_BERT_models/" rel="bookmark" title="NLP简报 [CH]: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,…">NLP简报 [CH]: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,…</a></h1>
        
      
    </div><!--/ .headline-wrap -->

    
    <div class="article-wrap">
      <p><img src="https://cdn-images-1.medium.com/max/2400/1*qaOM0D2tfy3chvnWRdycGA.png" alt="" /></p>

<p><br />
<strong>Thanks to <a href="https://blog.csdn.net/Kaiyuan_sjtu">Kaiyuan</a> (WeChat: NewBeeNLP) for this great translation.</strong></p>

<p><br />
欢迎来到 NLP 时事简报！涵盖了诸如特定语言 BERT 模型、免费数据集、深度学习库等主题。</p>

<h1 id="1publications-">1、Publications 📙</h1>

<p><strong>1.1 Language-specific BERT models</strong></p>

<p><br />
我已经记不清现在有多少种特定语言的 BERT 模型了，这里有一些最新的版本:</p>

<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>荷兰语 Dutch BERT（RobBERT[1]</td>
          <td>BERTje[2]）</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>德语 German BERT[3]</li>
  <li>葡萄牙语 Portuguese BERT[4]</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>法语（CamemBERT[5]</td>
          <td>FlauBERT[6]）</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>意大利语（AlBERTo[7]</td>
          <td>UmBERTo[8]）</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>西班牙语（BETO[9]）</li>
  <li>阿拉伯语（araBERT[10]）</li>
</ul>

<p><br />
大多数这些模型也可以通过 huggingFace 的Transformer 库[11]获得，该库最近升级到了2.4.1[12]。</p>

<p><br />
<strong>1.2 Overly Optimistic Prediction Results on Imbalanced Data: Flaws and Benefits of Applying Over-sampling</strong></p>

<p><br />
这篇论文[13]揭示并广泛讨论了在对数据集进行划分之前应用过采样来处理不平衡数据集的缺点和优点。此外，该工作复现了先前的研究，并确定了导致过于乐观的结果的方法论缺陷。</p>

<p><br />
<strong>1.3 Encode, Tag and Realize: A Controllable and Efficient Approach for Text Generation</strong></p>

<p><br />
为了减少基于 seq2seq 的文本生成方法中常见的 hallucination [14]（产生输入文本不支持的输出）的影响，Google 工程师公开了一种称为LaserTagger[15]的文本生成方法。该方法的主要思想是通过使用预测的编辑操作（例如<code class="highlighter-rouge">KEEP</code>，<code class="highlighter-rouge">DELETE-ADD</code>等）标记单词并在所谓的realization step中将其应用于输入单词来产生输出。</p>

<p><br />
这代替了通常只从头生成输出的文本生成方法，这种方法通常很慢而且容易出错。该模型除了产生更少的错误外，还提供了其他好处，例如，在进行少量训练示例的情况下，可以在实现并行预测的同时进行编辑操作，同时仍保持良好的准确性并优于 BERT baseline。</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/1600/0*OJN4pNgrQoS2STAX.png" alt="" /></p>

<p><br />
<strong>1.4 Convolutional Neural Networks as a Model of the Visual System: Past, Present, and Future</strong></p>

<p><br />
Grace Lindsay 发布了这份关于 CNN 历史的精美且易于阅读的报告[16]，以及如何将它们作为生物视觉的模型进行评估，即 CNN 表示与大脑的表示相比如何？强烈建议读者关注这份利用 CNN 进行视觉研究的讨论。</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/1600/1*SngMqzPQJigR5A3AzeJGDQ.png" alt="" /></p>

<p><br />
<strong>1.5 Multilingual Denoising Pre-training for Neural Machine Translation</strong></p>

<p><br />
Facebook AI 发布了mBART[17]，一种基于多语言 seq2seq 去噪自动编码器的方法，该方法在大规模单语言语料库上进行了预训练，可用于 25 种语言的机器翻译。这项工作遵循 Lewis 等人（BART，2019）的预训练方案，并研究了去噪预训练对韩文，日文和土耳其文等多种语言的影响。输入文本涉及对短语的掩盖和对句子的置换（加噪），学习了一种基于 Transformer 的模型跨多种语言重建文本。完整的自回归模型仅训练一次，并且可以在任何语言对上进行微调而无需进行任何特定于任务或特定于语言的修改。此外，解决了文档级和句子级的翻译问题。除了表现出性能提升外，作者还声称该方法在低资源机器翻译方面效果很好。</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/1600/1*aigX70Om2rEaI7OoTcpyGA.png" alt="" /></p>

<p><br />
<strong>1.6 On improving conversational agents</strong></p>

<p><br />
Meena[18]是一种 neural conversational agents，旨在进行更明智和更具体的改进对话 — — 定义为从人类对话中捕获重要属性（例如，流畅度）的指标。该模型通过编码器学习会话上下文，并通过解码器制定合理的响应。据报道，通过考虑使用更强大的解码器可以提高通话质量。</p>

<p><br />
你也可以了解更多 Alan Nichol（Rasa HQ 的联合创始人）关于这项工作的想法[19]。</p>

<h1 id="2creativity-and-society-">2、Creativity and Society 🎨</h1>

<p><strong>2.1 ML tools — reading comprehension test and sentiment analyzer</strong></p>

<p><br />
Ming Cheuk 构建了这个有趣的应用程序Albert Learns to Read[20]，可以测试经过深度学习方法训练的模型的阅读理解能力，尤其是使用 Google AI 的语言模型ALBERT[21]。ALBERT 是 BERT 的微型版本，用于学习语言表示。作者在博客 Teaching Machines to Read[22]详细介绍了该项目和使用的方法。</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/1600/1*kgKeL3svHqScr0Wjnfe0Cg.png" alt="" /></p>

<p><br />
<strong>2.2 A Self-Taught AI Researcher at Google</strong></p>

<p><br />
在这个采访A Self-Taught AI Researcher at Google[23]中，你可以直接从 Google Art＆Culture 的 ML 研究人员 Emil 那里听到有关他作为一名自学成才的研究人员从事 AI 事业的经历。</p>

<h1 id="3tools-and-datasets-️">3、Tools and Datasets ⚙️</h1>

<p><strong>3.1 Free Datasets</strong></p>

<p><br />
Google 数据集搜索[24]正式退出测试版，现在可提供多达 2500 万个数据集进行搜索。如果你想获得下一个数据科学或机器学习项目的灵感，那么这里是查找对整个 Internet 上托管的数据集的引用的地方。它基本上是用于数据集的搜索引擎，这是一项了不起的工作，需要付出巨大的努力！</p>

<p><br />
Big Bad NLP 数据库[25]是一个网站，你可以在其中搜索 200 多种 NLP 数据集的专用数据库，以执行诸如常识，情感分析，问题回答，蕴含推理等任务。</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/1600/1*uYwA0snqOdKYyTJ56edtyA.png" alt="" /></p>

<p><br />
<strong>3.2 Reinforcement learning library</strong></p>

<p><br />
最近，Chris Nota 开发并发布了PyTorch 库[26]，用于基于流行的深度 RL 算法（例如 DQN，PPO 和 DDPG 等）来构建强化学习代理。该库的重点是面向对象的设计，并能够快速实施和评估新型强化学习代理。</p>

<p><br />
<strong>3.3 ML Explainability and Interpretability</strong></p>

<p><br />
如果你当前正在使用基于文本的语言模型，并且想了解在应用于不同语言任务时如何更轻松地解释它们，那么你可能会对Captum[27]感兴趣。Captum 是一个可解释性库，可用于分析功能重要性，解释文本和视觉模型，解释多峰模型以及其他模型（例如用于回答问题的 BERT）。</p>

<p><br />
如果你对模型的可解释性感兴趣，那么这套教程[28]也可能会让您感兴趣。它包括通过 notebook 了解功能重要性的方法。</p>

<p><br />
<strong>3.4 Machine learning and deep learning libraries</strong></p>

<p><br />
Google Research 团队发布了Flax[29]，一种基于JAX[30]的灵活而强大的神经网络库，该库提供了使用典型的 Numpy API 进行快速计算和训练机器学习模型的框架。</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/1600/1*LSWFZM-xMV-GnvGl_lC-sg.png" alt="" /></p>

<p><br />
Thinc[31]是由 spaCy 的开发者开发的轻量级深度学习库。它提供了功能编程 API，用于组成，配置和部署使用 PyTorch 和 TensorFlow 之类的库构建的自定义模型。</p>

<p><br />
Lyft 发布了Flyte[32]，它是一个多租户，可用于生产的无服务器平台，用于部署并发，可伸缩和可维护的 ML 和数据处理工作流。</p>

<p><br />
<strong>3.5 A tool for conversational AI</strong></p>

<p><br />
开源对话式 AI 框架DeepPavlov[33]为构建对话系统和复杂的对话系统提供了免费且易于使用的解决方案。DeepPavlov 带有几个预定义的组件，用于解决与 NLP 相关的问题。它将 BERT（包括会话 BERT）集成到三个下游任务中：文本分类，命名实体识别（和一般的序列标记）以及问题解答。结果，它在所有这些任务上都取得了重大改进。(Google Colab[34] | Blog[35] | Demo[36])</p>

<h1 id="4ethics-in-ai-">4、Ethics in AI 🚨</h1>

<p><strong>4.1 Facial recognition and privacy</strong></p>

<p><br />
纽约时报针对与面部识别技术有关的隐私的不同观点撰写了一篇有趣的报告。这个故事的重点是一个名为“ Clearview”的“秘密公司”，据称该公司使用 AI 技术通过从 Twitter，Facebook 和 YouTube 等社交媒体网站上抓取的图像来构建通用的面部识别。所述技术引起了人们对隐私的担忧，但是据称它还主要用于执法。点击此处[37]阅读更多故事。</p>

<p><br />
<strong>4.2 Human-Level AI Progress</strong></p>

<p><br />
Jeremy Kahn 在这个报告[38]中广泛讨论了在 AI 技术的当前发展背景下“ Narrow AI”和“ General AI”之间的区别。除了讨论的许多主题之外，关于（如果可能的话）实现 AGI 的回报还有很多问题。该报告还提到了大型高科技公司最近对这些努力进行投资的兴趣。最值得注意的是，该报告包括一些受人尊敬的研究人员提出的一些担忧，他们声称某些试图操纵 AI 叙述以利于他们的研究组织表现出“不负责任和不道德”的行为。</p>

<p><br />
<strong>4.3 Understanding AI Ethics and Safety</strong></p>

<p><br />
Dr.David Leslie 发表了这份非常详尽的报告[39]，主题涉及有助于在道德和安全方面更好地理解人工智能的主题。它旨在帮助开发人员和研究人员更好地为公共部门设计和实施 AI 系统。</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/1600/1*Ye09aVDP93RKsLc12PXqNQ.png" alt="" /></p>

<h1 id="5articles-and-blog-posts-️">5、Articles and Blog posts ✍️</h1>

<p><strong>5.1 Speeding up tokenization tutorial</strong></p>

<p><br />
Steven van de Graaf 撰写了这篇文章[40]，报告说，与使用 Transformers 中的标准内置标记器相比，使用HuggingFace 的新 Tokenizer 库[41]的性能有所提高。Steven 报告说，其速度提高了 9 倍，并且实现过程花费了 10.6 秒来标记 100 万个句子。</p>

<p><br />
<strong>5.2 Can language models really comprehend?</strong></p>

<p><br />
The Gradient 最近在Gary Marcus 的这篇文章[42]中发表，他讨论了他认为是 GPT-2 等语言模型背后的基本缺陷的内容。Gary Marcus 的主要观点是，经过训练能够预测下一个单词的模型不一定是可以理解或推理的模型，即“预测是理解的组成部分，而不是整体。” 他还讨论了在语言环境中先天性的重要性，并指出当前的语言模型没有考虑到这一点。</p>

<p><br />
<strong>5.3 Curriculum for Reinforcement Learning</strong></p>

<p><br />
设计基于课程的方法可以帮助 RL agent 学习吗？Lillian Weng 总结了几种基于课程的方法[43]，以及如何利用它们来培训有效的强化学习代理。Weng 讨论了设计高效的课程学习方法所面临的挑战，该方法通常需要对任务的复杂性进行排序，并向模型提供一系列任务，这些任务会增加培训过程中的难度。</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/1600/0*B-t_sNMjKiOb_Y3Z.png" alt="" /></p>

<p><br />
<strong>5.4 Introduction to NumPy</strong></p>

<p><br />
我总是推荐任何机器学习入门的人来使用 NumPy 进行大量练习。当今，许多用于深度学习和机器学习的高级库都以某种方式使用 NumPy API，因此它是内部了解的非常重要的工具。Anne Bonner 最近发布了这个非常详细的 numpy 教程[44]，介绍了 NumPy 的基础。</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/1600/0*FmUSU_dh-_cqGUk_.png" alt="" /></p>

<h1 id="6education-">6、Education 🎓</h1>

<p><strong>6.1 Foundations of machine learning and statistical inference</strong></p>

<p><br />
来自加州理工学院的 Anima Anandkumar 发布了一门名为“机器学习和统计推论的基础”的课程。该课程侧重于 ML 概念，例如矩阵，张量，优化，概率模型，神经网络等。这是一门很棒的课程，因为它侧重于 ML 的理论方面，这对于理解和改进更高级的方法同样重要。（视频播放列表[45]|课程提纲[46]）</p>

<p><br />
<strong>6.2 Deep Learning Lecture Series</strong></p>

<p><br />
DeepMind 与 UCL 合作发布了深度学习讲座系列[47]，其中包括 12 个讲座，这些讲座将由 DeepMind 的领先研究科学家进行。主题包括如何使用注意力，记忆力和生成模型等方法训练神经网络。</p>

<p><br />
<strong>6.3 Open Syllabus</strong></p>

<p><br />
教育是不断发展的社区和整个行业的重要组成部分， 这是种植创新种子的地方。Open Syllabus[48]是一个非营利性组织，它利用众包的力量将高等教育课程映射到一个免费的在线数据库中。它目前包含大约 700 万个教学大纲。</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/1600/1*fwQIhfb2VWuwQJM_LaLehg.png" alt="" /></p>

<p><br />
<strong>6.4 Discussing, Sharing, and Learning about ML</strong></p>

<p><br />
r/ResearchML[49]是用于讨论 ML 论文的新的机器学习子目录。这一主题更侧重于研究并鼓励更深入的讨论。</p>

<p><br />
PracticalAI[50]是一个网站，你可以在其中浏览和发现由社区和专家策划的 ML 主题。</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/1600/1*UYxTqc60FHsPEU4bY5y74Q.png" alt="" /></p>

<h1 id="7notable-mentions-️">7、Notable Mentions ⭐️</h1>

<p>How we built the good first issues feature[51]：了解有关 GitHub 如何利用机器学习为开发人员发现简单和个性化问题的更多信息，以便他们可以解决与他们的兴趣相匹配的问题。这鼓励了来自开源贡献者的更快和更多的贡献。</p>

<p><br />
紧跟 Sebastian Ruder 的 NLP News[52]，以获取最新的 NLP 最新新闻。重点包括 NLP 进展的更新，过去十年的回顾，新的 NLP 课程以及其他主题。</p>

<p><br />
一份超赞的TensorFlow 2.0 深度学习 notebook[53]列表，范围从 CycleGAN 到 Transformers 到图像字幕任务。它们由 LBNL 的科学学院深度学习公开发布。</p>

<p><br />
一篇令人印象深刻且易于理解的博客文章，解释了贝叶斯神经网络[54]的基础，入门的绝佳介绍。</p>

<p><br />
An Opinionated Guide to ML Research[55]：John Schulman 就如何更好地选择研究问题以及在实施和解决手头的研究任务方面更具战略性等方面，为即将到来的机器学习研究人员提供了一些建议，还分享了个人发展和持续进步的技巧。</p>

<p><br />
今日限定款分割线，右下角链接可以阅读原文~</p>

<h1 id="本文参考资料">本文参考资料</h1>
<hr />

<p>[1] <strong>RobBERT:</strong> <a href="https://arxiv.org/abs/2001.06286">https://arxiv.org/abs/2001.06286</a></p>

<p><br />
[2] <strong>BERTje:</strong> <a href="https://arxiv.org/abs/1912.09582">https://arxiv.org/abs/1912.09582</a></p>

<p><br />
[3] <strong>德语 German BERT:</strong> <a href="https://deepset.ai/german-bert">https://deepset.ai/german-bert</a></p>

<p><br />
[4] <strong>葡萄牙语 Portuguese BERT:</strong> <a href="https://github.com/neuralmind-ai/portuguese-bert">https://github.com/neuralmind-ai/portuguese-bert</a></p>

<p><br />
[5] <strong>CamemBERT:</strong> <a href="https://arxiv.org/abs/1911.03894">https://arxiv.org/abs/1911.03894</a></p>

<p><br />
[6] <strong>FlauBERT:</strong> <a href="https://arxiv.org/abs/1912.05372">https://arxiv.org/abs/1912.05372</a></p>

<p><br />
[7] <strong>AlBERTo:</strong> <a href="http://ceur-ws.org/Vol-2481/paper57.pdf">http://ceur-ws.org/Vol-2481/paper57.pdf</a></p>

<p><br />
[8] <strong>UmBERTo:</strong> <a href="https://github.com/musixmatchresearch/umberto">https://github.com/musixmatchresearch/umberto</a></p>

<p><br />
[9] <strong>BETO:</strong> <a href="https://github.com/dccuchile/beto">https://github.com/dccuchile/beto</a></p>

<p><br />
[10] <strong>araBERT:</strong> <a href="https://colab.research.google.com/drive/1KSy89fAkWt6EGfnFQElDjXrBror9lIZh">https://colab.research.google.com/drive/1KSy89fAkWt6EGfnFQElDjXrBror9lIZh</a></p>

<p><br />
[11] <strong>Transformer 库:</strong> <a href="https://huggingface.co/models">https://huggingface.co/models</a></p>

<p><br />
[12] <strong>2.4.1:</strong> <a href="https://github.com/huggingface/transformers/releases">https://github.com/huggingface/transformers/releases</a></p>

<p><br />
[13] <strong>论文:</strong> <a href="https://arxiv.org/abs/2001.06296">https://arxiv.org/abs/2001.06296</a></p>

<p><br />
[14] <strong>hallucination :</strong> <a href="https://arxiv.org/abs/1910.08684">https://arxiv.org/abs/1910.08684</a></p>

<p><br />
[15] <strong>LaserTagger:</strong> <a href="https://ai.googleblog.com/2020/01/encode-tag-and-realize-controllable-and.html">https://ai.googleblog.com/2020/01/encode-tag-and-realize-controllable-and.html</a></p>

<p><br />
[16] <strong>报告:</strong> <a href="https://arxiv.org/abs/2001.07092">https://arxiv.org/abs/2001.07092</a></p>

<p><br />
[17] <strong>mBART:</strong> <a href="https://arxiv.org/pdf/2001.08210.pdf">https://arxiv.org/pdf/2001.08210.pdf</a></p>

<p><br />
[18] <strong>Meena:</strong> <a href="https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html">https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html</a></p>

<p><br />
[19] <strong>关于这项工作的想法:</strong> <a href="https://venturebeat.com/2020/01/31/with-googles-meena-are-ai-assistants-about-to-get-a-lot-smarter/">https://venturebeat.com/2020/01/31/with-googles-meena-are-ai-assistants-about-to-get-a-lot-smarter/</a></p>

<p><br />
[20] <strong>Albert Learns to Read:</strong> <a href="https://littlealbert.now.sh/#/">https://littlealbert.now.sh/#/</a></p>

<p><br />
[21] <strong>ALBERT:</strong> <a href="https://ai.googleblog.com/2019/12/albert-lite-bert-for-self-supervised.html">https://ai.googleblog.com/2019/12/albert-lite-bert-for-self-supervised.html</a></p>

<p><br />
[22] <strong>博客 Teaching Machines to Read:</strong> <a href="https://www.spark64.com/post/machine-comprehension">https://www.spark64.com/post/machine-comprehension</a></p>

<p><br />
[23] <strong>A Self-Taught AI Researcher at Google:</strong> <a href="https://blog.floydhub.com/emils-story-as-a-self-taught-ai-researcher/">https://blog.floydhub.com/emils-story-as-a-self-taught-ai-researcher/</a></p>

<p><br />
[24] <strong>Google 数据集搜索:</strong> <a href="https://blog.google/products/search/discovering-millions-datasets-web/">https://blog.google/products/search/discovering-millions-datasets-web/</a></p>

<p><br />
[25] <strong>Big Bad NLP 数据库:</strong> <a href="https://quantumstat.com/dataset/dataset.html">https://quantumstat.com/dataset/dataset.html</a></p>

<p><br />
[26] <strong>PyTorch 库:</strong> <a href="https://github.com/cpnota/autonomous-learning-library">https://github.com/cpnota/autonomous-learning-library</a></p>

<p><br />
[27] <strong>Captum:</strong> <a href="https://captum.ai/">https://captum.ai/</a></p>

<p><br />
[28] <strong>这套教程:</strong> <a href="https://www.kaggle.com/learn/machine-learning-explainability">https://www.kaggle.com/learn/machine-learning-explainability</a></p>

<p><br />
[29] <strong>Flax:</strong> <a href="https://github.com/google-research/flax/tree/prerelease">https://github.com/google-research/flax/tree/prerelease</a></p>

<p><br />
[30] <strong>JAX:</strong> <a href="https://github.com/google/jax">https://github.com/google/jax</a></p>

<p><br />
[31] <strong>Thinc:</strong> <a href="https://thinc.ai/">https://thinc.ai/</a></p>

<p><br />
[32] <strong>Flyte:</strong> <a href="https://eng.lyft.com/introducing-flyte-cloud-native-machine-learning-and-data-processing-platform-fb2bb3046a59">https://eng.lyft.com/introducing-flyte-cloud-native-machine-learning-and-data-processing-platform-fb2bb3046a59</a></p>

<p><br />
[33] <strong>DeepPavlov:</strong> <a href="https://github.com/deepmipt/DeepPavlov">https://github.com/deepmipt/DeepPavlov</a></p>

<p><br />
[34] <strong>Google Colab:</strong> <a href="https://colab.research.google.com/github/deepmipt/dp_notebooks/blob/master/DP_tf.ipynb">https://colab.research.google.com/github/deepmipt/dp_notebooks/blob/master/DP_tf.ipynb</a></p>

<p><br />
[35] <strong>Blog:</strong> <a href="https://medium.com/tensorflow/deeppavlov-an-open-source-library-for-end-to-end-dialog-systems-and-chatbots-31cf26849e37">https://medium.com/tensorflow/deeppavlov-an-open-source-library-for-end-to-end-dialog-systems-and-chatbots-31cf26849e37</a></p>

<p><br />
[36] <strong>Demo:</strong> <a href="https://demo.deeppavlov.ai/#/en/textqa">https://demo.deeppavlov.ai/#/en/textqa</a></p>

<p><br />
[37] <strong>此处:</strong> <a href="https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html">https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html</a></p>

<p><br />
[38] <strong>这个报告:</strong> <a href="https://fortune.com/longform/ai-artificial-intelligence-big-tech-microsoft-alphabet-openai/">https://fortune.com/longform/ai-artificial-intelligence-big-tech-microsoft-alphabet-openai/</a></p>

<p><br />
[39] <strong>这份非常详尽的报告:</strong> <a href="https://www.turing.ac.uk/sites/default/files/2019-06/understanding_artificial_intelligence_ethics_and_safety.pdf">https://www.turing.ac.uk/sites/default/files/2019-06/understanding_artificial_intelligence_ethics_and_safety.pdf</a></p>

<p><br />
[40] <strong>这篇文章:</strong> <a href="https://towardsdatascience.com/a-small-timing-experiment-on-the-new-tokenizers-library-a-write-up-7caab6f80ea6">https://towardsdatascience.com/a-small-timing-experiment-on-the-new-tokenizers-library-a-write-up-7caab6f80ea6</a></p>

<p><br />
[41] <strong>HuggingFace 的新 Tokenizer 库:</strong> <a href="https://github.com/huggingface/tokenizers">https://github.com/huggingface/tokenizers</a></p>

<p><br />
[42] <strong>Gary Marcus 的这篇文章:</strong> <a href="https://thegradient.pub/gpt2-and-the-nature-of-intelligence/">https://thegradient.pub/gpt2-and-the-nature-of-intelligence/</a></p>

<p><br />
[43] <strong>几种基于课程的方法:</strong> <a href="https://lilianweng.github.io/lil-log/2020/01/29/curriculum-for-reinforcement-learning.html">https://lilianweng.github.io/lil-log/2020/01/29/curriculum-for-reinforcement-learning.html</a></p>

<p><br />
[44] <strong>非常详细的 numpy 教程:</strong> <a href="https://numpy.org/devdocs/user/absolute_beginners.html">https://numpy.org/devdocs/user/absolute_beginners.html</a></p>

<p><br />
[45] <strong>视频播放列表:</strong> <a href="https://www.youtube.com/playlist?list=PLVNifWxslHCDlbyitaLLYBOAEPbmF1AHg">https://www.youtube.com/playlist?list=PLVNifWxslHCDlbyitaLLYBOAEPbmF1AHg</a></p>

<p><br />
[46] <strong>课程提纲:</strong> <a href="http://tensorlab.cms.caltech.edu/users/anima/cms165-2020.html">http://tensorlab.cms.caltech.edu/users/anima/cms165-2020.html</a></p>

<p><br />
[47] <strong>深度学习讲座系列:</strong> <a href="https://www.eventbrite.co.uk/o/ucl-x-deepmind-deep-learning-lecture-series-general-29078980901">https://www.eventbrite.co.uk/o/ucl-x-deepmind-deep-learning-lecture-series-general-29078980901</a></p>

<p><br />
[48] <strong>Open Syllabus:</strong> <a href="https://opensyllabus.org/">https://opensyllabus.org/</a></p>

<p><br />
[49] <strong>r/ResearchML:</strong> <a href="https://www.reddit.com/r/ResearchML/">https://www.reddit.com/r/ResearchML/</a></p>

<p><br />
[50] <strong>PracticalAI:</strong> <a href="https://practicalai.me/explore/content/">https://practicalai.me/explore/content/</a></p>

<p><br />
[51] <strong>How we built the good first issues feature:</strong> <a href="https://github.blog/2020-01-22-how-we-built-good-first-issues/">https://github.blog/2020-01-22-how-we-built-good-first-issues/</a></p>

<p><br />
[52] <strong>NLP News:</strong> <a href="http://newsletter.ruder.io/issues/nlp-progress-restrospectives-and-look-ahead-new-nlp-courses-independent-research-initiatives-interviews-lots-of-resources-217744">http://newsletter.ruder.io/issues/nlp-progress-restrospectives-and-look-ahead-new-nlp-courses-independent-research-initiatives-interviews-lots-of-resources-217744</a></p>

<p><br />
[53] <strong>TensorFlow 2.0 深度学习 notebook:</strong> <a href="https://github.com/NERSC/dl4sci-tf-tutorials">https://github.com/NERSC/dl4sci-tf-tutorials</a></p>

<p><br />
[54] <strong>贝叶斯神经网络:</strong> <a href="https://engineering.papercup.com/posts/bayesian-neural-nets/">https://engineering.papercup.com/posts/bayesian-neural-nets/</a></p>

<p><br />
[55] <strong>An Opinionated Guide to ML Research:</strong> <a href="http://joschu.net/blog/opinionated-guide-ml-research.html">http://joschu.net/blog/opinionated-guide-ml-research.html</a></p>

      <hr />
      <footer role="contentinfo">
        <div class="social-share">
  <!-- Go to www.addthis.com/dashboard to customize your tools --> 
  <div class="addthis_inline_share_toolbox"></div>
  <!--
  <h4>Share on</h4>
  <ul>
    <li>
      <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/NLP%E7%AE%80%E6%8A%A5_Flax,_Thinc,_Language-specific_BERT_models/" class="twitter" title="Share on Twitter"><i class="fa fa-twitter"></i><span> Twitter</span></a>
    </li>
    <li>
      <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/NLP%E7%AE%80%E6%8A%A5_Flax,_Thinc,_Language-specific_BERT_models/" class="facebook" title="Share on Facebook"><i class="fa fa-facebook"></i><span> Facebook</span></a>
    </li>
    <li>
      <a href="https://plus.google.com/share?url=http://localhost:4000/NLP%E7%AE%80%E6%8A%A5_Flax,_Thinc,_Language-specific_BERT_models/" class="google-plus" title="Share on Google Plus"><i class="fa fa-google-plus"></i><span> Google+</span></a>
    </li>
  </ul>-->
</div><!-- /.social-share -->
        <p class="byline"><strong>NLP简报 [CH]: Flax, Thinc, Language-specific BERT models, Meena, Flyte, LaserTagger,…</strong> was published on <time datetime="2020-02-15T00:00:00+01:00">February 15, 2020</time>.</p>
        
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dair-ai'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<!--
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->

      </footer>
    </div><!-- /.article-wrap -->
  
    <section id="disqus_thread"></section><!-- /#disqus_thread -->
  
  </article>
</div><!-- /#main -->

<div class="footer-wrap">
  
  <div class="related-articles">
  <h4>You might also enjoy <small class="pull-right">(<a href="http://localhost:4000/posts/">View all posts</a>)</small></h4>
    <ul>
    
      <li><a href="http://localhost:4000/NLP_Newsletter_NLP_7-ZH-.md/" title="NLP 简报（Issue#7）: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…">NLP 简报（Issue#7）: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…</a></li>
    
      <li><a href="http://localhost:4000/NLP_Newsletter_NLP_7/" title="NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…">NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…</a></li>
    
      <li><a href="http://localhost:4000/NLP_Newsletter_-7_-FR/" title="NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…">NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…</a></li>
    
    </ul>
    <hr />
  </div><!-- /.related-articles -->
  
  <footer>
    

<span>&copy; 2020 dair.ai. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="http://mademistakes.com/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a> theme.</span>

  </footer>
</div><!-- /.footer-wrap -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>

<!-- Asynchronous Google Analytics snippet -->
<script>
  var _gaq = _gaq || [];
  var pluginUrl =
 '//www.google-analytics.com/plugins/ga/inpage_linkid.js';
  _gaq.push(['_require', 'inpage_linkid', pluginUrl]);
  _gaq.push(['_setAccount', 'UA-158959084-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<script async defer src="https://buttons.github.io/buttons.js"></script>


  
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dair-ai'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<!--
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->




</body>
</html>
