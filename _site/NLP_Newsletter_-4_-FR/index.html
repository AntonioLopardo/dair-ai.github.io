<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->

<head>
<meta charset="utf-8">
<title>NLP Newsletter [FR] #4: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,… &#8211; dair.ai</title>
<meta name="description" content="">
<meta name="keywords" content="nlp_newsletter">


<!-- Twitter Cards -->
<meta name="twitter:title" content="NLP Newsletter [FR] #4: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,…">
<meta name="twitter:description" content="">
<meta name="twitter:site" content="@dair_ai">


<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://dair.ai/images/nlp_newsletter_4.png">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP Newsletter [FR] #4: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,…">
<meta property="og:description" content="">
<meta property="og:url" content="https://dair.ai/NLP_Newsletter_-4_-FR/">
<meta property="og:site_name" content="dair.ai">

<meta property="og:image" content="https://dair.ai/images/nlp_newsletter_4.png">







<link rel="canonical" href="https://dair.ai/NLP_Newsletter_-4_-FR/">
<link href="https://dair.ai/feed.xml" type="application/atom+xml" rel="alternate" title="dair.ai Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="https://dair.ai/assets/css/main.css">

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
	<script src="https://dair.ai/assets/js/vendor/html5shiv.min.js"></script>
	<script src="https://dair.ai/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="https://dair.ai/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<link href='//fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700%7CPT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="https://dair.ai/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="https://dair.ai/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="https://dair.ai/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://dair.ai/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://dair.ai/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://dair.ai/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body class="post">

<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.8&appId=1537934899816329";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>

<!-- Go to www.addthis.com/dashboard to customize your tools -->
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-4e43ef4f23bf37b0"></script>

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
		<a href="https://dair.ai/">dair.ai</a>
	</div><!-- /.site-name -->
	<div class="top-navigation">
		<nav role="navigation" id="site-nav" class="nav">
		    <ul>
		        
				    
				    <li><a href="https://dair.ai/posts/" >Blog ✍️</a></li>
				
				    
				    <li><a href="https://dair.ai/about/" >About ℹ️</a></li>
				
				    
				    <li><a href="https://dair.ai/newsletter/" >NLP Newsletter 🗞️</a></li>
				
				    
				    <li><a href="https://dair.ai/projects/" >Projects 💡</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai" target="_blank">GitHub 📁</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/dair-ai.github.io/contribute" target="_blank">Contribute ✨</a></li>
				
				    
				    <li><a href="https://medium.com/dair-ai" target="_blank">Medium 📰</a></li>
				
				    
				    <li><a href="https://nlpoverview.com/" target="_blank">NLP Overview 📘</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/nlp_highlights" target="_blank">2019 NLP Highlights (PDF) 🔥</a></li>
				
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->



<div id="main" role="main">
  <div class="article-author-side">
    

<div itemscope itemtype="http://schema.org/Person">


	<img src="https://dair.ai/images/lbourdois.png" class="bio-photo" alt="Loïck BOURDOIS bio photo">


  <h3 itemprop="name">Loïck BOURDOIS</h3>
  <p>Data Scientist working at the Bordeaux Population Health Research Centre of INSERM University of Bordeaux.</p>

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
</div>

  </div>
  <article class="post">
    <div class="headline-wrap">
      
        
          <h1><a href="https://dair.ai/NLP_Newsletter_-4_-FR/" rel="bookmark" title="NLP Newsletter [FR] #4: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,…">NLP Newsletter [FR] #4: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,…</a></h1>
        
      
    </div><!--/ .headline-wrap -->

    
    <div class="article-wrap">
      <p><img src="https://cdn-images-1.medium.com/max/1200/1*3vNKhz6K-oGQ8aLi3mo84Q.png" alt="" /></p>

<h1 id="publications-">Publications 📙</h1>
<p><strong><em>Turing-NLG: Un modèle linguistique de 17 milliards de paramètres par Microsoft</em></strong></p>

<p><br />
Turing Natural Language Generation (T-NLG) est un modèle de 17 milliards de paramètres <a href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/">proposé</a> par les chercheurs en IA de Microsoft. Il est à ce jour, le plus grand modèle de langage connu (illustré dans la figure ci-dessous) et est basé sur un Transformer à 78 couches qui surpasse les résultats précédents (détenus par Megatron-LM de NVIDIA) sur la perplexité de WikiText-103. Il a été testé sur des tâches telles que la réponse à des questions et le résumé abstrait. Le modèle est rendu possible par une librairie d’optimisation de l’entraînement appelée DeepSpeed avec ZeRO, qui est également présentée plus loin dans cette newsletter.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*CAZm7uj8EaupnvnJ.png" alt="" /></p>

<p><a href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/"><em>source</em></a></p>

<p><br />
<strong><em>Neural based Dependency Parsing</em></strong></p>

<p><br />
Miryam de Lhoneux a publié sa thèse de doctorat intitulée “<a href="http://uu.diva-portal.org/smash/record.jsf?pid=diva2%3A1357373&amp;dswid=7905">Linguistically Informed Neural Dependency Parsing for Typologically Diverse Languages</a>”. Ce travail porte sur l’utilisation d’approches neurales pour l’<a href="http://nlpprogress.com/english/dependency_parsing.html">analyse des dépendances</a> dans les langues typologiquement diverses (c’est-à-dire les langues qui construisent et expriment le sens de manière structurellement différente). Ce travail rapporte que les RNN et les couches récursives pourraient être utiles pour l’incorporation dans les parsers car elles aident à informer les modèles avec des connaissances linguistiques importantes nécessaires pour l’analyse. D’autres idées comprennent l’utilisation de l’analyse syntaxique polyglotte et des stratégies de partage de paramètres pour l’analyse syntaxique dans des langues apparentées et non apparentées.</p>

<p><br />
<strong><em>Extraction d’informations de bout en bout dans le cloud avec BERT</em></strong></p>

<p><br />
Une équipe de chercheurs a publié un <a href="https://arxiv.org/abs/2002.01861">article</a> décrivant comment des modèles de Transformers comme BERT peuvent aider à l’extraction d’informations de bout en bout dans des documents commerciaux spécifiques à un domaine, tels que les dépôts réglementaires et les contrats de location de propriété. Non seulement ce type de travail peut aider à optimiser les opérations commerciales, mais il montre également l’applicabilité et l’efficacité des modèles basés sur BERT sur des régimes avec très peu de données annotées. Une application, et ses détails de mise en œuvre, qui fonctionne sur le cloud est également proposée (voir figure ci-dessous).</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*KqViSLhP0otleDY-XFy3Bg.png" alt="" /></p>

<p><a href="https://arxiv.org/abs/2002.01861"><em>source</em></a></p>

<p><br />
<strong><em>Question Answering Benchmark</em></strong></p>

<p><br />
<a href="https://arxiv.org/abs/2001.11770v1">Wolfson et al. (2020)</a> ont publié un benchmark pour la compréhension des questions ainsi qu’une méthode pour décomposer une question qui est nécessaire pour calculer une réponse appropriée. Ils s’appuient sur le crowdsourcing pour annoter les étapes nécessaires à la décomposition des questions. Pour montrer la faisabilité et l’applicabilité de l’approche, ils améliorent la réponse aux questions du domaine ouvert en utilisant l’ensemble de données HotPotQA.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*AztG-Inqt6LGQ87lSufRcw.png" alt="" /></p>

<p> <a href="https://arxiv.org/pdf/2001.11770v1.pdf"><em>source</em></a></p>

<p><br />
<strong><em>Données radioactives : le traçage par l’entraînement</em></strong></p>

<p><br />
Les chercheurs de Facebook AI ont récemment publié un <a href="https://ai.facebook.com/blog/using-radioactive-data-to-detect-if-a-data-set-was-used-for-training/">travail</a> qui vise à marquer les images (appelées données radioactives) afin de vérifier si un jeu de données particulier a été utilisé pour l’entraînement d’un modèle de ML. Ils ont découvert qu’il est possible d’utiliser un marqueur intelligent qui déplace les caractéristiques dans une direction, que le modèle utilise pour aider à détecter l’utilisation de données radioactives même si seulement 1 % des données d’entraînement sont radioactives. C’est un défi car tout changement dans les données peut potentiellement dégrader la précision du modèle. Selon les auteurs, ce travail peut « aider les chercheurs et les ingénieurs à savoir quel jeu de données a été utilisé pour entraîner un modèle, afin de mieux comprendre comment les différents ensembles de données affectent les performances des différents réseaux neuronaux ». Cette approche semble importante pour les applications critiques de ML. Consultez le document complet <a href="https://arxiv.org/pdf/2002.00937.pdf">ici</a>.</p>

<p><br />
<strong><em>REALM: Retrieval-Augmented Language Model Pre-Training</em></strong></p>

<p><br />
<a href="https://kentonl.com/pub/gltpc.2020.pdf">REALM</a> est une approche d’extraction à grande échelle qui utilise un corpus de connaissances textuelles pour pré-entraîner un modèle de langue de manière non supervisée. Les tâches abordées et évaluées à l’aide de REALM comprennent des questions ouvertes répondant à des critères de référence. Outre l’amélioration de la précision du modèle, les autres avantages comprennent les composantes de modularité et d’interprétabilité.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*MJO-yzCwsB5ydKGz7hKHVA.png" alt="" /></p>

<p><a href="https://kentonl.com/pub/gltpc.2020.pdf"><em>source</em></a></p>

<h1 id="créativité-et-société-">Créativité et société 🎨</h1>

<p><strong><em>Permettre la présentation à distance de documents et d’affiches lors de conférences scientifiques</em></strong></p>

<p><br />
La semaine dernière, une <a href="https://www.change.org/p/organizers-of-data-science-and-machine-learning-conferences-neurips-icml-aistats-iclr-uai-allow-remote-paper-poster-presentations-at-conferences">pétition</a> a été lancée pour permettre la présentation à distance de documents et d’affiches lors de conférences scientifiques comme celles liées au ML. Il semble que Yoshua Bengio, plaide pour que les gens aillent signer la pétition. Il l’a clairement indiqué dans son nouveau <a href="https://yoshuabengio.org/2020/02/10/fusce-risus/">blog</a>.</p>

<p><br />
<strong><em>Défi de l’abstraction et du raisonnement</em></strong></p>

<p><br />
François Chollet a récemment mis en ligne un <a href="https://www.kaggle.com/c/abstraction-and-reasoning-challenge/overview">concours Kaggle</a> où il a publié le Corpus d’abstraction et de raisonnement (ARC). Il vise à encourager les utilisateurs à créer des systèmes d’IA capables de résoudre des tâches de raisonnement auxquelles ils n’ont jamais été exposés. L’espoir est de commencer à construire des systèmes d’IA plus robustes, capables de résoudre mieux et rapidement de nouveaux problèmes par eux-mêmes, ce qui pourrait aider à résoudre les applications du monde réel les plus difficiles, comme l’amélioration des voitures autonomes.</p>

<p><br />
<strong><em>Publications de ML et NLP en 2019</em></strong></p>

<p><br />
Marek Rei publie son <a href="https://www.marekrei.com/blog/ml-and-nlp-publications-in-2019/">analyse annuelle</a> sur les statistiques en lien avec l’apprentissage machine et le NLP pour l’année 2019. Les conférences incluses dans l’analyse sont ACL, EMNLP, NAACL, EACL, COLING, TACL, CL, CoNLL, NeurIPS, ICML, ICLR, et AAAI.</p>

<p><br />
<strong><em>La croissance d’automates cellulaires neuronaux</em></strong></p>

<p><br />
La morphogenèse est un processus d’auto-organisation par lequel certaines créatures comme les salamandres peuvent se régénérer ou réparer des dommages corporels. Ce processus est robuste aux perturbations et de nature adaptative. Inspirés par ce phénomène biologique et par le besoin de mieux comprendre le processus, les chercheurs ont publié un <a href="https://distill.pub/2020/growing-ca/">article</a> intitulé “Growing Neural Cellular Automata”, qui adopte un modèle différenciable pour la morphogenèse visant à reproduire les comportements et les propriétés des systèmes d’autoréparation. L’espoir est de pouvoir construire des machines autoréparatrices qui possèdent la même robustesse et plasticité que la vie biologique. En outre, cela permettrait de mieux comprendre le processus de régénération lui-même. Les applications qui peuvent en bénéficier comprennent la médecine régénératrice et la modélisation des systèmes sociaux et biologiques.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*2p62h1RaHD6d11LX8olnTA.png" alt="" /></p>

<p><a href="https://distill.pub/2020/growing-ca/"><em>source</em></a></p>

<p><br />
<strong><em>Visualiser l’attention des Transformers</em></strong></p>

<p><br />
Hendrik Strobelt a partagé ce <a href="https://github.com/SIDN-IAP/attnvis">repertoire</a> qui montre comment construire rapidement une visualisation interactive simple de l’attention d’un Transformer à travers une application web en utilisant la bibliothèque HuggingFace et d3.js.</p>

<p><br />
<strong><em>SketchTransfer : Une nouvelle tâche stimulante pour explorer l’invariance des détails et les abstractions apprises par les réseaux</em></strong></p>

<p><br />
<a href="https://arxiv.org/pdf/1912.11570.pdf">SketchTransfer</a> propose une nouvelle tâche pour tester la capacité des réseaux neuronaux à supporter l’invariance en présence/absence de détails. On a longtemps débattu du fait que les réseaux ne peuvent pas se généraliser à des variations qui n’ont pas encore été observées pendant l’entraînement, comme par exemple traiter les détails visuels manquants lorsqu’ils regardent des dessins animés. Le document examine et publie un ensemble de données pour aider les chercheurs à étudier attentivement le problème de « l’invariance des détails » en fournissant des croquis non étiquetés et des exemples étiquetés d’images réelles.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*jdYuMoHiu2yya5rHzZyjwQ.png" alt="" /></p>

<p><a href="https://arxiv.org/pdf/1912.11570.pdf"><em>source</em></a></p>

<h1 id="outils-et-jeux-de-données-️">Outils et jeux de données ⚙️</h1>

<p><strong><em>DeepSpeed + ZeRO</em></strong></p>

<p><br />
Microsoft a dévoilée une librairie d’optimisation pour l’entrainement appelée DeepSpeed. Elle est compatible avec PyTorch et peut permettre l’entrainement d’un modèle de 100 milliards de paramètres. La librairie se concentre sur quatre aspects importants de l’entrainement d’un modèle : l’échelle, la vitesse, le coût et la convivialité. DeepSpeed a été <a href="https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/">lancé</a> en même temps que ZeRO. ZeRO est une technologie d’optimisation de la mémoire qui permet de faire du deep learning distribué à grande échelle sur GPU tout en améliorant le débit de trois à cinq fois plus que le meilleur système actuel.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*MXDI1f3cSBrY5w2g.gif" alt="" /></p>

<p><a href="https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/"><em>source</em></a></p>

<p><br />
<strong><em>Une librairie pour mener des recherches rapides et efficaces sur le DL en 3D</em></strong></p>

<p><br />
<a href="https://ai.facebook.com/blog/-introducing-pytorch3d-an-open-source-library-for-3d-deep-learning/">PyTorch3D</a> est une boîte à outils open-source pour la recherche sur le DL en 3D. La librairie consiste en des implémentations rapides et optimisées d’opérateurs 3D et de fonctions de perte fréquemment utilisés. Elle est également dotée d’un moteur de rendu modulaire et différenciable qui permet de mener des recherches sur des entrées 3D complexes et de faire des prévisions 3D de haute qualité.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*VbspKMmPBUsgpdnIkd5jYA.png" alt="" /></p>

<p><a href="https://ai.facebook.com/blog/-introducing-pytorch3d-an-open-source-library-for-3d-deep-learning/"><em>source</em></a></p>

<p><br />
<strong><em>Gestion de la configuration de projets de ML</em></strong></p>

<p><br />
Hydra est un outil pour gérer plus efficacement les projets de ML complexes. Il est destiné à aider les chercheurs de PyTorch en offrant une réutilisation fonctionnelle des configurations. Son principal avantage est qu’il permet au programmeur de gérer la configuration comme du code de composition, ce qui signifie que le fichier de configuration peut être facilement écrasé. Hydra peut également aider à gérer automatiquement le répertoire de travail des résultats de votre projet de ML, ce qui est utile lorsque vous avez besoin de sauvegarder et d’accéder aux résultats de plusieurs expériences pour des travaux multiples. Pour en savoir plus, cliquez <a href="https://medium.com/pytorch/hydra-a-fresh-look-at-configuration-for-machine-learning-projects-50583186b710">ici</a>.</p>

<p><br />
<strong><em>Une boîte à outils pour l’inférence causale avec les réseaux bayésiens</em></strong></p>

<p><br />
<a href="https://causalnex.readthedocs.io/en/latest/01_introduction/01_introduction.html">CausalNex</a> est une boîte à outils pour “l’inférence causale avec les réseaux bayésiens”. L’outil vise à combiner l’apprentissage machine et le raisonnement causal pour découvrir des relations structurelles dans les données. Les auteurs ont également préparé un guide d’introduction sur le pourquoi et le comment de l’inférence causale avec les réseaux bayésiens en utilisant la librairie Python proposée.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*EYwKhdnscR7ZLuNkTqCS2Q.png" alt="" /></p>

<p><a href="https://causalnex.readthedocs.io/en/latest/01_introduction/01_introduction.html"><em>source</em></a></p>

<p><br />
<strong><em>Google Colab Pro est maintenant disponible</em></strong></p>

<p><br />
Google Colab propose désormais une édition Pro, qui offre des avantages tels qu’un accès exclusif à des GPU et TPU plus rapides, des durées d’exécution plus longues et plus de mémoire.</p>

<p><br />
<strong><em>TyDi QA: Un benchmark pour le Question/Anwsering multilingues</em></strong></p>

<p><br />
Google AI publie <a href="https://ai.googleblog.com/2020/02/tydi-qa-multilingual-question-answering.html">TyDi QA</a>, un ensemble de données multilingues qui peut encourager les chercheurs à répondre à des questions dans des langues plus typologiquement diverses. C’est à dire qui construisent et expriment le sens de différentes manières. L’idée est de motiver les chercheurs à construire des modèles plus robustes sur des langues typologiquement éloignées, telles que l’arabe, le bengali, le coréen, le russe, le télougou et le thaï, afin de généraliser à encore plus de langues.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*1dZv5you3jigdrQ2uAKzUw.png" alt="" /></p>

<p><a href="https://ai.googleblog.com/2020/02/tydi-qa-multilingual-question-answering.html"><em>source</em></a></p>

<p><br />
<strong><em>Question Answering pour Node.js</em></strong></p>

<p><br />
Hugging Face publie une <a href="https://github.com/huggingface/node-question-answering">librairie</a> de questions/réponses basée sur DistilBERT. Ce modèle peut fonctionner en production en utilisant Node.js avec seulement 3 lignes de code. Le modèle tire parti de la mise en œuvre rapide de Tokenizers, et de TensorFlow.js (une bibliothèque populaire pour l’utilisation de modèles d’apprentissage machine avec Javascript).</p>

<h1 id="ethique-en-ia-">Ethique en IA 🚨</h1>

<p><strong><em>Identifier les biais subjectifs dans les textes</em></strong></p>

<p><br />
Ce <a href="https://podcasts.apple.com/us/podcast/will-ai-help-identify-bias-or-perpetuate-it-with-diyi-yang/id1435564422?i=1000464141922">podcast</a> présente Diyi Yang, chercheur en sciences sociales computationnelles, qui explique comment les systèmes d’IA peuvent aider à identifier les biais subjectifs dans les informations textuelles. Il s’agit d’un domaine de recherche important impliquant les systèmes d’IA et de NLP. En particulier lorsque nous discutons de la consommation de médias textuels tels que les news qui peuvent être facilement encadrés pour biaiser les consommateurs alors qu’en réalité ils devraient viser à être plus objectifs. Du point de vue de l’application, il devient essentiel d’identifier automatiquement le biais subjectif présent dans les médias textuels afin d’aider les consommateurs à devenir plus conscients du contenu qu’ils consomment. L’épisode traite également de la manière dont l’IA peut également perpétuer le biais.</p>

<p><br />
<strong><em>Intelligence artificielle, valeurs et alignement</em></strong></p>

<p><br />
L’essor des systèmes d’IA et la manière dont ils s’alignent sur les valeurs humaines est un domaine de recherche actif qui implique l’éthique dans les systèmes d’IA. DeepMind a récemment publié un <a href="https://deepmind.com/research/publications/Artificial-Intelligence-Values-and-Alignment">papier</a> qui examine plus en profondeur les questions philosophiques entourant l’alignement de l’IA. Le rapport se concentre sur deux parties :  technique (c’est-à-dire comment coder les valeurs qui rendent les résultats des agents d’IA fiables) et normative (quels principes seraient justes à coder dans l’IA). Le document préconise une approche fondée sur des principes visant à préserver à préserver un traitement équitable malgré la différence de croyances et d’opinions.</p>

<p><br />
<strong><em>Sur l’audit des systèmes d’IA</em></strong></p>

<p><br />
VentureBeat rapporte que Google Researchers, en collaboration avec d’autres groupes, a créé un framework appelé SMACTR qui permet aux ingénieurs de vérifier les systèmes d’IA. La raison de ce travail est de combler le fossé de responsabilité qui existe avec les systèmes d’IA actuels qui sont mis dans la nature pour être utilisés par les consommateurs. Pour plus d’informations, lire les deux documents suivants :  <a href="https://venturebeat.com/2020/01/30/google-researchers-release-audit-framework-to-close-ai-accountability-gap/">ici</a> et <a href="https://dl.acm.org/doi/abs/10.1145/3351095.3372873">ici</a>.</p>

<h1 id="articles-et-blog-️">Articles et Blog ✍️</h1>

<p><strong><em>La distillation de modèle en NLP</em></strong></p>

<p><br />
Dans un <a href="https://soundcloud.com/nlp-highlights/104-model-distillation-with-victor-sanh-and-thomas-wolf">podcast</a> de NLP Highlights, Thomas Wolf et Victor Sanh parlent de la distillation de modèles et de la façon dont elle peut être utilisée comme une approche réalisable pour comprimer de grands modèles comme BERT. Ce concept est discuté plus en détail dans la méthode qu’ils proposent, appelée <a href="https://arxiv.org/abs/1910.01108">DistilBERT</a>, dans laquelle ils construisent des modèles plus petits (basés sur la même architecture qu’un modèle plus grand) pour essayer d’imiter le comportement du modèle plus grand. En substance, le petit modèle (l’étudiant) essaie de s’adapter à la distribution de probabilité de l’enseignant.</p>

<p><br />
<em>**BERT, ELMo, &amp; GPT-2: Dans quelle mesure les représentations contextuelles des mots sont-elles contextualisées ? **</em></p>

<p><br />
On a beaucoup parlé du succès des méthodes contextualisées comme BERT pour aborder une grande variété de tâches complexes de NLP. Dans cet <a href="https://kawine.github.io/blog/nlp/2020/02/03/contextual.html">article</a>, Kawin Ethayarajh tente de répondre à la question qui consiste à savoir comment sont contextualisés les mots dans les modèles comme BERT, ELMo et le GPT-2. Les sujets abordés comprennent les mesures de la contextualité, la spécificité du contexte et les comparaisons entre les embeddings statiques et les représentations contextualisées.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*70aIv1Fkkz4rnHgQ.png" alt="" /></p>

<p><a href="https://kawine.github.io/blog/nlp/2020/02/03/contextual.html"><em>source</em></a></p>

<p><br />
<strong><em>Sparsity in Neural Networks</em></strong></p>

<p><br />
François Lagunas, a écrit cet <a href="https://medium.com/huggingface/is-the-future-of-neural-networks-sparse-an-introduction-1-n-d03923ecbd70">article Medium</a> pour discuter de son optimisme quant à l’adoption de tenseurs clairsemés dans les modèles de réseaux de neurones. L’espoir est d’utiliser une forme de rareté pour réduire la taille des modèles actuels qui, à un moment donné, deviennent peu pratiques en raison de leur taille et de leur vitesse. Ce concept pourrait être intéressant à explorer en ML en raison de la taille même des modèles actuels comme les Transformers. Cependant, les détails de mise en œuvre ne sont pas aussi clairs du point de vue des outils de développement disponibles, et c’est quelque chose sur lequel la communauté travaille déjà.</p>

<p><br />
<strong><em>Entraîner votre propre modèle linguistique</em></strong></p>

<p><br />
Si vous souhaitez apprendre à entrainer un modèle de zéro, consultez ce <a href="https://huggingface.co/blog/how-to-train">tutoriel</a> d’Hugging Face. Ils utilisent évidemment leurs propres bibliothèques Transformers et Tokenizers pour entraîner le modèle.</p>

<p><br />
<strong><em>Tokenizers: Comment les machines lisent</em></strong></p>

<p><br />
Cathal Horan a publié un <a href="https://blog.floydhub.com/tokenization-nlp/">article</a> sur la manière dont les modèles de NLP les plus récents utilisent les tokenizers. Il explique également pourquoi la tokenisation est un domaine de recherche actif, passionnant et important. L’article vous montre même comment entraîner vos propres tokenizers en utilisant des méthodes de tokenisation comme SentencePiece et WordPiece.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*Vkjw5n9Sz0Was43haVNJMg.png" alt="" /></p>

<p><a href="https://blog.floydhub.com/tokenization-nlp/%27"><em>source</em></a></p>

<h1 id="education-">Education 🎓</h1>

<p><strong><em>ML à l’université d’Amsterdam</em></strong></p>

<p><br />
Vous pouvez désormais suivre en ligne le <a href="https://mlvu.github.io/">cours d’apprentissage machine 2020 MLVU</a>, qui comprend des diapositives, des <a href="https://www.youtube.com/watch?v=excCZSTJEPs&amp;feature=youtu.be">vidéos</a> et le programme. Il s’agit d’une introduction au ML, mais il comporte également d’autres sujets liés à l’apprentissage approfondi, tels que les VAE et les GAN.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*zFpU2rQL5Fby7X3boJyQNg.png" alt="" /></p>

<p><a href="https://mlvu.github.io/"><em>source</em></a></p>

<p><br />
<strong><em>Ressources mathématiques pour le ML</em></strong></p>

<p><br />
Suzana Ilić et le Machine Learning Tokyo (MLT) ont fait un travail remarquable en termes de démocratisation de l’éducation au ML. Par exemple, consultez ce <a href="https://github.com/Machine-Learning-Tokyo/Math_resources">répertoire</a> qui présente une collection de ressources en ligne gratuites pour apprendre les fondements des concepts mathématiques utilisés en ML.</p>

<p><br />
<strong><em>Introduction au Deep Learning</em></strong></p>

<p><br />
Suivez le cours “Introduction to Deep Learning” du MIT sur ce <a href="http://introtodeeplearning.com/">site</a>. De nouveaux cours seront publiés chaque semaine et toutes les diapositives, vidéos et codes seront publiés.</p>

<p><br />
<strong><em>Deep Learning avec PyTorch</em></strong></p>

<p><br />
Alfredo Canziani a publié les diapositives et les notebooks pour son mini-cours sur l’apprentissage profond avec PyTorch. Le dépôt contient également un <a href="https://atcold.github.io/pytorch-Deep-Learning/">site web complémentaire</a> qui comprend des descriptions textuelles des concepts enseignés dans le cours.</p>

<p><br />
<strong><em>Missing Semester of Your CS</em></strong></p>

<p><br />
Le “<a href="https://missing.csail.mit.edu/">Missing Semester of Your CS</a>” est un cours en ligne pouvant être utile aux spécialistes des données ayant une formation autre que celle du développement. Il comprend des sujets tels que les outils shell, les scripts et le contrôle de version. Le cours a été publié par des membres du corps enseignant du MIT.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*weUnTXxmHxYf-B2DDaslvw.png" alt="" /></p>

<p><a href="https://missing.csail.mit.edu/2020/shell-tools/"><em>source</em></a></p>

<p><br />
<strong><em>Deep Learning avancé</em></strong></p>

<p><br />
La CMU a publié les diapositives et le programme du cours “<a href="https://andrejristeski.github.io/10707-S20/syllabus.html">Advanced Deep Learning</a>” qui comprend des sujets tels que les modèles autorégressifs, les modèles générateurs et l’apprentissage autosurveillé/prédictif. Le cours s’adresse aux étudiants de master ou de doctorat ayant une formation avancée en ML.</p>

<h1 id="mentions-spéciales-️">Mentions spéciales ⭐️</h1>

<p>Xu et ses collaborateurs (2020) ont proposé une <a href="https://arxiv.org/abs/2002.02925">méthode</a> pour remplacer et compresser progressivement un modèle BERT en le divisant en ses composantes d’origine. Le modèle proposé surpasse les autres approches de distillation sur le référentiel GLUE.</p>

<p><br />
Le cours “<a href="https://compstat-lmu.github.io/lecture_i2ml/index.html">Introduction à l’apprentissage machine</a>” couvre les bases du ML, la régression supervisée, les forêts aléatoires, le tuning des paramètres et bien d’autres sujets fondamentaux du ML.</p>

<p><br />
Le modèle grec de BERT (<a href="https://huggingface.co/nlpaueb/bert-base-greek-uncased-v1">GreekBERT</a>) est maintenant disponible sur Transformers.</p>

<p><br />
Jeremy Howard publie un <a href="https://arxiv.org/abs/2002.04688">article</a> décrivant la librairie fastai. Il s’agit d’une lecture recommandée aux développeurs de logiciels qui travaillent à la création et à l’amélioration des librairies d’apprentissage profond et de ML.</p>

<p><br />
Deeplearning.ai complète la publication des quatre cours de TensorFlow : <a href="https://www.coursera.org/specializations/tensorflow-data-and-deployment">Data and Deployment Specialization</a>. Cette spécialisation vise principalement à apprendre aux développeurs comment déployer efficacement des modèles dans différents scénarios et utiliser les données de manière intéressante.</p>

<p><br />
Sebastian Raschka a récemment publié un <a href="https://arxiv.org/abs/2002.04803">article</a> intitulé “Machine Learning in Python” : Principaux développements et tendances technologiques en matière de science des données, d’apprentissage automatique et d’intelligence artificielle”. Ce document est un examen complet du paysage des outils d’apprentissage machine. Il permet de comprendre les avantages de certaines librairies et les concepts utilisés dans l’ingénierie ML. En outre, un mot sur l’avenir des bibliothèques d’apprentissage machine basées sur Python est fourni.</p>

<hr />

<p>Vous pouvez retrouver la précédente newsletter <a href="https://dair.ai/NLP_Newsletter_-3_-FR/">ici</a></p>

<p><br />
Si vous avez des jeux de données, des projets, des articles de blog, des tutoriels ou des documents que vous souhaitez partager dans la prochaine édition de la newletter, n’hésitez pas à me contacter à ellfae@gmail.com ou par message sur <a href="https://twitter.com/omarsar0">Twitter</a>.</p>

<p><br />
<a href="https://dair.ai/newsletter/">Abonnez-vous</a> pour recevoir les prochains numéros dans votre boîte mail.</p>

      <hr />
      <footer role="contentinfo">
        <div class="social-share">
  <!-- Go to www.addthis.com/dashboard to customize your tools --> 
  <div class="addthis_inline_share_toolbox"></div>
  <!--
  <h4>Share on</h4>
  <ul>
    <li>
      <a href="https://twitter.com/intent/tweet?text=https://dair.ai/NLP_Newsletter_-4_-FR/" class="twitter" title="Share on Twitter"><i class="fa fa-twitter"></i><span> Twitter</span></a>
    </li>
    <li>
      <a href="https://www.facebook.com/sharer/sharer.php?u=https://dair.ai/NLP_Newsletter_-4_-FR/" class="facebook" title="Share on Facebook"><i class="fa fa-facebook"></i><span> Facebook</span></a>
    </li>
    <li>
      <a href="https://plus.google.com/share?url=https://dair.ai/NLP_Newsletter_-4_-FR/" class="google-plus" title="Share on Google Plus"><i class="fa fa-google-plus"></i><span> Google+</span></a>
    </li>
  </ul>-->
</div><!-- /.social-share -->
        <p class="byline"><strong>NLP Newsletter [FR] #4: PyTorch3D, DeepSpeed, Turing-NLG, Question Answering Benchmarks, Hydra, Sparse Neural Networks,…</strong> was published on <time datetime="2020-03-09T00:00:00-05:00">March 09, 2020</time>.</p>
        
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dair-ai'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<!--
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->

      </footer>
    </div><!-- /.article-wrap -->
  
    <section id="disqus_thread"></section><!-- /#disqus_thread -->
  
  </article>
</div><!-- /#main -->

<div class="footer-wrap">
  
  <div class="related-articles">
  <h4>You might also enjoy <small class="pull-right">(<a href="https://dair.ai/posts/">View all posts</a>)</small></h4>
    <ul>
    
      <li><a href="https://dair.ai/NLP_Newsletter_NLP_7-ZH-.md/" title="NLP 简报（Issue#7）: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…">NLP 简报（Issue#7）: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…</a></li>
    
      <li><a href="https://dair.ai/NLP_Newsletter_NLP_7/" title="NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…">NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…</a></li>
    
      <li><a href="https://dair.ai/NLP_Newsletter_-7_-FR/" title="NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…">NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…</a></li>
    
    </ul>
    <hr />
  </div><!-- /.related-articles -->
  
  <footer>
    

<span>&copy; 2020 dair.ai. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="http://mademistakes.com/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a> theme.</span>

  </footer>
</div><!-- /.footer-wrap -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="https://dair.ai/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="https://dair.ai/assets/js/scripts.min.js"></script>

<!-- Asynchronous Google Analytics snippet -->
<script>
  var _gaq = _gaq || [];
  var pluginUrl =
 '//www.google-analytics.com/plugins/ga/inpage_linkid.js';
  _gaq.push(['_require', 'inpage_linkid', pluginUrl]);
  _gaq.push(['_setAccount', 'UA-158959084-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<script async defer src="https://buttons.github.io/buttons.js"></script>


  
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dair-ai'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<!--
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->




</body>
</html>
