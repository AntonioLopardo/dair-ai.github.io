<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->

<head>
<meta charset="utf-8">
<title>NLP Newsletter [FR] #5: The Annotated GPT-2, Understanding self-distillation, Haiku, GANILLA, Sparkwiki, Ethics in NLP, Torchmeta,… &#8211; dair.ai</title>
<meta name="description" content="">
<meta name="keywords" content="nlp_newsletter">


<!-- Twitter Cards -->
<meta name="twitter:title" content="NLP Newsletter [FR] #5: The Annotated GPT-2, Understanding self-distillation, Haiku, GANILLA, Sparkwiki, Ethics in NLP, Torchmeta,…">
<meta name="twitter:description" content="">
<meta name="twitter:site" content="@dair_ai">


<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://dair.ai/images/nlp_newsletter_5.png">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP Newsletter [FR] #5: The Annotated GPT-2, Understanding self-distillation, Haiku, GANILLA, Sparkwiki, Ethics in NLP, Torchmeta,…">
<meta property="og:description" content="">
<meta property="og:url" content="https://dair.ai/NLP_Newsletter_-5_-FR/">
<meta property="og:site_name" content="dair.ai">

<meta property="og:image" content="https://dair.ai/images/nlp_newsletter_5.png">







<link rel="canonical" href="https://dair.ai/NLP_Newsletter_-5_-FR/">
<link href="https://dair.ai/feed.xml" type="application/atom+xml" rel="alternate" title="dair.ai Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="https://dair.ai/assets/css/main.css">

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
	<script src="https://dair.ai/assets/js/vendor/html5shiv.min.js"></script>
	<script src="https://dair.ai/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="https://dair.ai/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<link href='//fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700%7CPT+Serif:400,700,400italic' rel='stylesheet' type='text/css'>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="https://dair.ai/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="https://dair.ai/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="https://dair.ai/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://dair.ai/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://dair.ai/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://dair.ai/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body class="post">

<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.8&appId=1537934899816329";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>

<!-- Go to www.addthis.com/dashboard to customize your tools -->
<script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-4e43ef4f23bf37b0"></script>

<!--[if lt IE 9]><div class="browser-upgrade alert alert-info">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]-->

<div class="navigation-wrapper">
	<div class="site-name">
		<a href="https://dair.ai/">dair.ai</a>
	</div><!-- /.site-name -->
	<div class="top-navigation">
		<nav role="navigation" id="site-nav" class="nav">
		    <ul>
		        
				    
				    <li><a href="https://dair.ai/posts/" >Blog ✍️</a></li>
				
				    
				    <li><a href="https://dair.ai/about/" >About ℹ️</a></li>
				
				    
				    <li><a href="https://dair.ai/newsletter/" >NLP Newsletter 🗞️</a></li>
				
				    
				    <li><a href="https://dair.ai/projects/" >Projects 💡</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai" target="_blank">GitHub 📁</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/dair-ai.github.io/contribute" target="_blank">Contribute ✨</a></li>
				
				    
				    <li><a href="https://medium.com/dair-ai" target="_blank">Medium 📰</a></li>
				
				    
				    <li><a href="https://nlpoverview.com/" target="_blank">NLP Overview 📘</a></li>
				
				    
				    <li><a href="https://github.com/dair-ai/nlp_highlights" target="_blank">2019 NLP Highlights (PDF) 🔥</a></li>
				
		    </ul>
		</nav>
	</div><!-- /.top-navigation -->
</div><!-- /.navigation-wrapper -->



<div id="main" role="main">
  <div class="article-author-side">
    

<div itemscope itemtype="http://schema.org/Person">


	<img src="https://dair.ai/images/lbourdois.png" class="bio-photo" alt="Loïck BOURDOIS bio photo">


  <h3 itemprop="name">Loïck BOURDOIS</h3>
  <p>Data Scientist working at the Bordeaux Population Health Research Centre of INSERM University of Bordeaux.</p>

  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
</div>

  </div>
  <article class="post">
    <div class="headline-wrap">
      
        
          <h1><a href="https://dair.ai/NLP_Newsletter_-5_-FR/" rel="bookmark" title="NLP Newsletter [FR] #5: The Annotated GPT-2, Understanding self-distillation, Haiku, GANILLA, Sparkwiki, Ethics in NLP, Torchmeta,…">NLP Newsletter [FR] #5: The Annotated GPT-2, Understanding self-distillation, Haiku, GANILLA, Sparkwiki, Ethics in NLP, Torchmeta,…</a></h1>
        
      
    </div><!--/ .headline-wrap -->

    
    <div class="article-wrap">
      <p><img src="https://cdn-images-1.medium.com/max/1200/1*YIhZsPaiBFkRMMWo5FAhGw.png" alt="" /></p>

<h1 id="avant-propos">Avant-propos</h1>
<p>Tout d’abord, je ne saurais trop tous vous remercier pour le soutien et les encouragements incroyables que vous avez apportés à cette newsletter. Son élaboration nécessite des recherches et une rédaction fastidieuse que je trouve à la fois enrichissantes et utiles, afin de vous fournir le meilleur contenu. J’espère que vous les appréciez, car c’est le cas pour moi. 😉</p>

<h1 id="publications-">Publications 📙</h1>

<p><strong><em>Une compréhension théorique de l’autodistillation</em></strong></p>

<p><br />
L’<a href="https://arxiv.org/pdf/1503.02531.pdf">autodistillation</a> est le processus de transfert de connaissances d’une architecture à une seconde qui est identique. Les prédictions du modèle original sont transmises comme valeurs cibles au second modèle pendant la phase d’entraînement. Outre les propriétés souhaitables, comme la réduction de la taille du modèle, les résultats empiriques montrent que cette approche fonctionne bien sur des ensembles de données maintenus. Un groupe de chercheurs a récemment publié un article qui fournit une analyse théorique visant à mieux comprendre ce qui se passe dans ce processus et pourquoi il est efficace. Les résultats montrent que quelques cycles d’autodistillation amplifient la régularisation (<a href="https://twitter.com/TheGradient/status/1228132843630387201?s=20">en limitant progressivement le nombre de fonctions de base qui représentent la solution</a>), ce qui tend à réduire le sur-apprentissage. (Lire l’article complet <a href="https://arxiv.org/abs/2002.05715">ici</a>)</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*nWYO71awfooL4MrGK-tFww.png" alt="" /></p>

<p><a href="https://arxiv.org/abs/2002.05715"><em>source</em></a></p>

<p><br />
<strong><em>Les années 2010 : Une décennie d’apprentissage approfondi / Perspectives pour les années 2020</em></strong></p>

<p><br />
<a href="http://people.idsia.ch/~juergen/">Jürgen Schmidhuber</a>, un pionnier de l’intelligence artificielle, a récemment publié un <a href="http://people.idsia.ch/~juergen/2010s-our-decade-of-deep-learning.html">article sur son blog</a> qui se concentre sur un aperçu historique de l’apprentissage profond depuis 2010. Parmi les sujets abordés, citons les LSTM, les feedforward NN, les GAN, l’apprentissage par renforcement, le méta-apprentissage, la distillation, l’apprentissage par l’attention, etc. L’article se termine par une perspective sur les années 2020, encourageant l’attention sur des questions urgentes telles que la vie privée et les marchés des données.</p>

<p><br />
<strong><em>Utilisation des réseaux de neurones pour résoudre des équations mathématiques</em></strong></p>

<p><br />
Les chercheurs du FAIR de Facebook ont publié un <a href="https://arxiv.org/abs/1912.01412">article</a> qui propose un modèle entraîné sur des problèmes mathématiques ainsi que leurs solutions associées, afin d’apprendre à prédire les solutions possibles pour des tâches telles que la résolution de problèmes d’intégration. L’approche est basée sur une approche similaire à celle utilisée dans la traduction automatique où les expressions mathématiques sont représentées comme une sorte de langage et les solutions sont traitées comme le problème de traduction. Ainsi, au lieu que le modèle produise une traduction, le résultat est la solution elle-même. Les chercheurs affirment ainsi que les réseaux neuronaux profonds ne sont pas seulement bons pour le raisonnement symbolique, mais aussi pour des tâches plus diverses.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*P_JtxoC8pYkXuXCp3e3QeQ.png" alt="" /></p>

<p><em>Équations fournies en entrée avec la solution correspondante fournie par le modèle –</em> <a href="https://ai.facebook.com/blog/using-neural-networks-to-solve-advanced-mathematics-equations/"><em>source</em></a></p>

<h1 id="créativité-et-société-">Créativité et société 🎨</h1>

<p><strong><em>L’IA au service de la découverte scientifique</em></strong></p>

<p><br />
Mattew Hutson <a href="https://www.sciencemag.org/news/2020/02/models-galaxies-atoms-simple-ai-shortcuts-speed-simulations-billions-times">rapporte</a> comment l’IA peut être utilisée pour produire des émulateurs qui ont une utilité importante dans la modélisation de phénomènes naturels complexes qui pourraient, à leur tour, conduire à différents types de découvertes scientifiques. Le défi avec la construction de ces émulateurs est qu’ils nécessitent souvent d’importantes données et une exploration approfondie des paramètres. Un <a href="https://arxiv.org/abs/2001.08055">article</a> récent propose DENSE, une approche basée sur la <a href="https://en.wikipedia.org/wiki/Neural_architecture_search">recherche d’architecture neurale</a> pour construire des émulateurs précis tout en ne s’appuyant que sur une quantité limitée de données d’entraînement. Ils l’ont testée en effectuant des simulations pour des cas tels que l’astrophysique, la climatologie et la fusion, entre autres.</p>

<p><br />
<strong><em>Améliorer la « traduction » de l’image à l’illustration</em></strong></p>

<p><br />
GANILLA est une approche qui propose l’utilisation de GAN pour améliorer le transfert à la fois du style et du contenu dans la <a href="https://paperswithcode.com/task/image-to-image-translation">tâche de traduction d’image à image</a> non appariée. En particulier, un modèle d’illustration d’image à image est proposé (avec un réseau générateur amélioré) et évalué sur la base d’un nouveau cadre d’évaluation quantitative qui prend en compte à la fois le contenu et le style. La nouveauté de ce travail réside dans le réseau générateur proposé qui tient compte d’un équilibre entre le style et le contenu, ce que les modèles précédents n’ont pas réussi à atteindre. Des codes et modèles pré-entrainés sont mis à <a href="https://github.com/giddyyupp/ganilla">disposition</a>. Lisez le document complet <a href="https://arxiv.org/abs/2002.05638">ici</a>.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*l_B4vfaHVkXDwzM7SldiqQ.png" alt="" /></p>

<p><br />
<strong><em>Andrew Ng parle de l’intérêt pour l’auto-apprentissage</em></strong></p>

<p><br />
Andrew Ng, le fondateur de deeplearning.ai, est intervenu dans un podcast sur l’intelligence artificielle pour <a href="https://www.youtube.com/watch?v=0jspaMLxBig">parler</a> de sujets tels que ses débuts dans le ML, l’avenir de l’IA, l’enseignement de l’IA, ses recommandations pour une bonne utilisation du ML, ses objectifs personnels et les techniques de ML auxquelles il faudra prêter attention dans les années 2020.</p>

<p><br />
Andrew a expliqué pourquoi il est très enthousiaste à l’idée de s’initier à l’auto-apprentissage. <a href="https://lilianweng.github.io/lil-log/2019/11/10/self-supervised-learning.html">L’auto-apprentissage supervisé</a> consiste à formuler un problème d’apprentissage dont le but est d’obtenir une supervision à partir des données elles-mêmes. L’intérêt est d’utiliser de grandes quantités de données non labélisées, ce qui est plus disponibles en plus grande quantité que les données labélisées. Les représentations, par opposition à l’exécution de la tâche, sont importantes et peuvent être utilisées pour traiter des tâches en aval, comme c’est le cas dans les modèles linguistiques tels que le <a href="https://lilianweng.github.io/lil-log/2019/01/31/generalized-language-models.html#bert">BERT</a>.</p>

<p><br />
Il y a également beaucoup d’intérêt à utiliser l’auto-apprentissage supervisé](pour apprendre des représentations visuelles généralisées qui rendent les modèles plus précis dans des environnements à faibles ressources. Par exemple, une méthode récente appelée <a href="https://arxiv.org/abs/2002.05709">SimCLR</a> (dirigée par Geoffrey Hinton) propose un cadre pour améliorer les résultats de la classification des images dans différents contextes tels que l’apprentissage par transfert et l’apprentissage semi-supervisé.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*8zLzHFCyM3goc9y7KApHfg.png" alt="" /></p>

<p><a href="https://arxiv.org/abs/2002.05709"><em>source</em></a></p>

<h1 id="outils-et-jeux-de-données-️">Outils et jeux de données ⚙️</h1>

<p><strong><em>Les libraries liées à JAX</em></strong></p>

<p><br />
<a href="https://github.com/google/jax">JAX</a> est une nouvelle bibliothèque qui combine NumPy et la différenciation automatique pour mener des recherches de ML de haut niveau. Afin de simplifier les pipelines utilisant JAX, DeepMind a publié <a href="https://github.com/deepmind/dm-haiku">Haiku</a> et <a href="https://github.com/deepmind/rlax">RLax</a>. RLax simplifie l’implémentation de modèles basés sur l’apprentissage par renforcement et Haiku simplifie la construction de réseaux neuronaux en utilisant des modèles de programmation orientés objet.</p>

<p><br />
<strong><em>Un outil de traitement des données Wikipédia</em></strong></p>

<p><br />
<a href="https://github.com/epfl-lts2/sparkwiki">Sparkwiki</a> est un outil permettant de traiter les données de Wikipédia. Cette version s’inscrit dans le cadre de nombreux efforts visant à permettre des recherches intéressantes en matière d’analyse comportementale, telles que la <a href="https://arxiv.org/abs/2002.06885">capture des tendances et des biais linguistiques dans les différentes éditions linguistiques de Wikipédia</a>. Les auteurs ont découvert qu’indépendamment de la langue, le comportement de navigation des utilisateurs de Wikipédia montre qu’ils ont tendance à partager des intérêts communs comme par exemples les films, la musique et le sport, mais que les différences deviennent plus apparentes avec les événements locaux et les particularités culturelles.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*K7N9KbQlbuqowUeePjLtdw.jpeg" alt="" /></p>

<p><br />
<strong><em>Mise à jour de la librairie Transformers</em></strong></p>

<p><br />
Une <a href="https://github.com/huggingface/transformers/releases/tag/v2.5.0">nouvelle version</a> de la librairie Transformers d’Hugging Face est disponible. Elle comprend l’intégration de leur librairie Tokenizer qui vise à accélérer des modèles comme BERT, RoBERTa, GPT2, et d’autres modèles construits par la communauté.</p>

<h1 id="ethique-en-ia-">Ethique en IA 🚨</h1>

<p><strong><em>Considérations éthiques pour les modèles de NLP et de ML</em></strong></p>

<p><br />
Dans un nouvel <a href="https://soundcloud.com/nlp-highlights/106-ethical-considerations-in-nlp-research-emily-bender">épisode</a> des <a href="https://soundcloud.com/nlp-highlights">NLP Highlights</a>, Emily Bender et les intervenants parlent de certaines considérations éthiques qui peuvent se poser lors du développement de modèles de NLP dans un contexte d’utilisation universitaire et grand public. Parmi les sujets abordés, citons les considérations éthiques lors de la conception des tâches de NLP, les approches de collecte de données et, finalement, la publication des résultats.
En plus de toutes les considérations ci-dessus, une préoccupation qui est toujours discutée dans la communauté de l’IA est de se concentrer trop sur l’optimisation d’une mesure, ce qui va à l’encontre des fondements de ce que l’IA vise à atteindre (càd une IA générale). Rachel Thomas et David Uminsky discutent des erreurs possibles en <a href="https://arxiv.org/abs/2002.08512">analysant de manière approfondie</a> différents cas d’utilisation. Ils proposent également un cadre simple pour atténuer le problème, qui implique l’utilisation et la combinaison de plusieurs mesures, suivies par l’implication des personnes directement concernées par la technologie.</p>

<h1 id="articles-et-blog-️">Articles et Blog ✍️</h1>

<p><strong><em>Le GPT2 annoté</em></strong></p>

<p><br />
Aman Arora a récemment publié un article sur son blog, intitulé le “<a href="https://amaarora.github.io/2020/02/18/annotatedGPT2.html">The Annotated GPT-2</a>”, qui explique le fonctionnement interne du GPT-2. Son approche s’inspire de “<a href="https://nlp.seas.harvard.edu/2018/04/03/attention.html">The Annotated Transformer</a>” qui a adopté une approche d’annotation pour expliquer les parties importantes du modèle par le biais de code et d’explications faciles à suivre. Aman a fait de gros efforts pour réimplémenter le GPT-2 d’OpenAI en utilisant PyTorch et la bibliothèque Transformers de Hugging Face.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*oRFMJTEojyQ-uocVES5GYA.png" alt="" /></p>

<p><a href="https://amaarora.github.io/2020/02/18/annotatedGPT2.html"><em>source</em></a></p>

<p><br />
<strong><em>Au-delà de BERT ?</em></strong></p>

<p><br />
Sergi Castella expose son <a href="https://towardsdatascience.com/beyond-bert-6f51a8bc5ce1">point de vue</a> sur ce qui se trouve au-delà de BERT. Les principaux sujets abordés sont l’amélioration des mesures, la façon dont la librairie Transformers d’HuggingfFace permet de faire des recherches, les jeux de données intéressants à consulter, etc…</p>

<p><br />
<strong><em>Opérateur de compression matricielle</em></strong></p>

<p><br />
TensorFlow blog a publié un <a href="https://blog.tensorflow.org/2020/02/matrix-compression-operator-tensorflow.html?linkId=82298016">article</a> expliquant les techniques et l’importance de la compression des matrices dans un modèle de réseau neuronal profond. La compression des matrices peut aider à construire des modèles petits plus efficaces qui peuvent être incorporés dans des appareils tels que les téléphones et les assistants vocaux. En se concentrant sur la compression des modèles par des méthodes telles que la low-rank-approximation et la quantization, nous n’avons pas besoin de compromettre la qualité du modèle.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/1*fpAdJvBIf4SKxF3gTIpe_g.png" alt="" /></p>

<p><a href="https://blog.tensorflow.org/2020/02/matrix-compression-operator-tensorflow.html?linkId=82298016"><em>source</em></a></p>

<h1 id="education-">Education 🎓</h1>

<p><strong><em>Les bases du NLP</em></strong></p>

<p><br />
Elvis a publié une ébauche du chapitre 1 de sa nouvelle série intitulée “<a href="https://medium.com/dair-ai/fundamentals-of-nlp-chapter-1-tokenization-lemmatization-stemming-and-sentence-segmentation-b362c5d07684">Les bases du NLP</a>”. Il enseigne les concepts du NLP en partant des bases tout en partageant les meilleures pratiques, les références importantes, et les erreurs courantes à éviter. Un <a href="https://colab.research.google.com/drive/18ZnEnXKLQkkJoBXMZR2rspkWSm9EiDuZ">Google Colab</a> est disponible et le projet sera maintenu <a href="https://github.com/dair-ai/nlp_fundamentals">ici</a>.</p>

<p><br />
<strong><em>[Online] Review/Discussion: Part I Mathematical Foundations Reading Session</em></strong></p>

<p><br />
Machine Learning Tokyo organise une discussion en ligne sur les chapitres qui ont été couverts lors de leurs récentes sessions d’étude en ligne. Le groupe avait auparavant étudié des chapitres basés sur le livre intitulé <a href="https://mml-book.github.io/">Mathematics For Machine Learning</a>, écrit par Marc Peter Deisenroth, A Aldo Faisal et Cheng Soon Ong. L’événement est prévu pour le 8 mars 2020.</p>

<p><br />
<strong><em>Recommandations de livres</em></strong></p>

<p><br />
Dans une partie précédente, nous avons discuté de l’importance de la compression matricielle pour la construction de petits modèles de ML. Si vous souhaitez en savoir plus sur la façon de construire des réseaux neuronaux profonds plus petits pour les systèmes embarqués, consultez cet excellent livre intitulé <a href="https://tinymlbook.com/?linkId=82595412">TinyML</a>, écrit par Pete Warden et Daniel Situnayake.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*omOa3aw2bfMzX2Qm.jpg" alt="" /></p>

<p><a href="https://www.amazon.com/TinyML-Learning-TensorFlow-Ultra-Low-Micro-Controllers/dp/1492052043"><em>source</em></a></p>

<p><br />
Un autre livre intéressant à surveiller et qui est à paraître est “<a href="https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527">Deep Learning for Coders with fastai and PyTorch” : AI Applications Without a PhD</a>” de Jeremy Howard et Sylvain Gugger. Ce livre vise à fournir les bases mathématiques nécessaires pour construire et former des modèles permettant d’aborder des tâches dans les domaines de computer vision et du NLP.</p>

<p><br />
<img src="https://cdn-images-1.medium.com/max/800/0*i2OmtWOncatOYsZv.jpg" alt="" /></p>

<p><a href="https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527"><em>source</em></a></p>

<h1 id="mentions-spéciales-️">Mentions spéciales ⭐️</h1>

<p><a href="https://arxiv.org/abs/1909.06576">Torchmeta</a> est une librairie qui permet d’utiliser facilement des chargeurs de données connexes pour la recherche sur le méta-apprentissage. Elle a été rédigée par Tristan Deleu.</p>

<p><br />
Manuel Tonneau a écrit un <a href="https://creatext.ai/blog-posts/machine-text-writing-gpt2-beam-search?utm_medium=newsletter">article</a> offrant un regard plus approfondi sur certains des mécanismes impliqués dans la modélisation du langage. Parmi les sujets abordés, citons la greedy recherche, la beam recherche et l’échantillonnage de noyaux.</p>

<p><br />
Le MIT <a href="http://introtodeeplearning.com/">publie</a> le programme complet et le calendrier du cours intitulé “Introduction to Deep Learning”. L’objectif est de publier chaque semaine des vidéos et des diapositives.</p>

<p><br />
Apprenez comment entraîner un modèle de reconnaissance d’entités nommées (NER) en utilisant une approche basée sur <a href="https://github.com/huggingface/transformers/blob/master/examples/ner/run_pl_ner.py">Transformers</a> en moins de 300 lignes de code. Vous pouvez trouver le programme Google Colab qui l’accompagne <a href="https://colab.research.google.com/drive/184LPlygvdGGR64hgQl3ztqzZJu8MmITn">ici</a>.</p>

<hr />

<p>Vous pouvez retrouver la précédente newsletter <a href="https://dair.ai/NLP_Newsletter_-4_-FR/">ici</a></p>

<p><br />
Si vous avez des jeux de données, des projets, des articles de blog, des tutoriels ou des documents que vous souhaitez partager dans la prochaine édition de la newletter, n’hésitez pas à me contacter à ellfae@gmail.com ou par message sur <a href="https://twitter.com/omarsar0">Twitter</a>.</p>

<p><br />
<a href="https://dair.ai/newsletter/">Abonnez-vous</a> pour recevoir les prochains numéros dans votre boîte mail.</p>

      <hr />
      <footer role="contentinfo">
        <div class="social-share">
  <!-- Go to www.addthis.com/dashboard to customize your tools --> 
  <div class="addthis_inline_share_toolbox"></div>
  <!--
  <h4>Share on</h4>
  <ul>
    <li>
      <a href="https://twitter.com/intent/tweet?text=https://dair.ai/NLP_Newsletter_-5_-FR/" class="twitter" title="Share on Twitter"><i class="fa fa-twitter"></i><span> Twitter</span></a>
    </li>
    <li>
      <a href="https://www.facebook.com/sharer/sharer.php?u=https://dair.ai/NLP_Newsletter_-5_-FR/" class="facebook" title="Share on Facebook"><i class="fa fa-facebook"></i><span> Facebook</span></a>
    </li>
    <li>
      <a href="https://plus.google.com/share?url=https://dair.ai/NLP_Newsletter_-5_-FR/" class="google-plus" title="Share on Google Plus"><i class="fa fa-google-plus"></i><span> Google+</span></a>
    </li>
  </ul>-->
</div><!-- /.social-share -->
        <p class="byline"><strong>NLP Newsletter [FR] #5: The Annotated GPT-2, Understanding self-distillation, Haiku, GANILLA, Sparkwiki, Ethics in NLP, Torchmeta,…</strong> was published on <time datetime="2020-03-09T00:00:00-05:00">March 09, 2020</time>.</p>
        
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dair-ai'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<!--
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->

      </footer>
    </div><!-- /.article-wrap -->
  
    <section id="disqus_thread"></section><!-- /#disqus_thread -->
  
  </article>
</div><!-- /#main -->

<div class="footer-wrap">
  
  <div class="related-articles">
  <h4>You might also enjoy <small class="pull-right">(<a href="https://dair.ai/posts/">View all posts</a>)</small></h4>
    <ul>
    
      <li><a href="https://dair.ai/NLP_Newsletter_NLP_7-ZH-.md/" title="NLP 简报（Issue#7）: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…">NLP 简报（Issue#7）: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…</a></li>
    
      <li><a href="https://dair.ai/NLP_Newsletter_NLP_7/" title="NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…">NLP Newsletter: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…</a></li>
    
      <li><a href="https://dair.ai/NLP_Newsletter_-7_-FR/" title="NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…">NLP Newsletter [FR] #7: NLP Paper Summaries, Learning to Simulate, Transformers Notebooks, Med7, Measuring Compositional Generalization, Neural Tangents,…</a></li>
    
    </ul>
    <hr />
  </div><!-- /.related-articles -->
  
  <footer>
    

<span>&copy; 2020 dair.ai. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="http://mademistakes.com/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a> theme.</span>

  </footer>
</div><!-- /.footer-wrap -->

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="https://dair.ai/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="https://dair.ai/assets/js/scripts.min.js"></script>

<!-- Asynchronous Google Analytics snippet -->
<script>
  var _gaq = _gaq || [];
  var pluginUrl =
 '//www.google-analytics.com/plugins/ga/inpage_linkid.js';
  _gaq.push(['_require', 'inpage_linkid', pluginUrl]);
  _gaq.push(['_setAccount', 'UA-158959084-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<script async defer src="https://buttons.github.io/buttons.js"></script>


  
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'dair-ai'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<!--
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->




</body>
</html>
